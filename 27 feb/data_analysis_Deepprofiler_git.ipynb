{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49321141",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy tqdm scikit-learn umap-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS & CONFIG\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs/results/features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs/metadata/index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "REG_PARAM = 1e-2\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL DATA LOADING\n",
    "# ==========================================\n",
    "print(\"Loading Metadata...\")\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "site_level_data = []\n",
    "site_level_features = []\n",
    "\n",
    "print(f\"Loading features from {FEATURES_BASE}...\")\n",
    "for i in tqdm(meta.index, desc=\"Sites Processed\"):\n",
    "    filename = os.path.join(\n",
    "        FEATURES_BASE,\n",
    "        str(meta.loc[i, \"Metadata_Plate\"]),\n",
    "        str(meta.loc[i, \"Metadata_Well\"]),\n",
    "        f\"{meta.loc[i, 'Metadata_Site']}.npz\"\n",
    "    )\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    # Aggregation 1: Median per site\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Create Main DataFrame\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "\n",
    "# ==========================================\n",
    "# 3. WELL-LEVEL AGGREGATION (MEAN)\n",
    "# ==========================================\n",
    "# We keep wells separate to see the red no_sgRNA dots individually\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 4. SPHERING (ZCA WHITENING)\n",
    "# ==========================================\n",
    "def perform_sphering(df, ctrl_label, reg):\n",
    "    ctrl_wells = df[df[\"Treatment\"] == ctrl_label][feature_cols].values\n",
    "    if len(ctrl_wells) < 2:\n",
    "        print(\"Warning: Need at least 2 control wells for sphering.\")\n",
    "        return None\n",
    "    \n",
    "    mean_vec = np.mean(ctrl_wells, axis=0)\n",
    "    X_centered = df[feature_cols].values - mean_vec\n",
    "    \n",
    "    # Calculate ZCA Matrix\n",
    "    cov = np.dot((ctrl_wells - mean_vec).T, (ctrl_wells - mean_vec)) / (len(ctrl_wells) - 1)\n",
    "    evals, evecs = np.linalg.eigh(cov + reg * np.eye(cov.shape[0]))\n",
    "    zca_matrix = np.dot(evecs, np.dot(np.diag(1.0 / np.sqrt(evals + 1e-6)), evecs.T))\n",
    "    \n",
    "    return np.dot(X_centered, zca_matrix.T)\n",
    "\n",
    "# Prepare both datasets\n",
    "X_raw_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "X_sphered = perform_sphering(wells, CONTROL_NAME, REG_PARAM)\n",
    "\n",
    "# ==========================================\n",
    "# 5. UMAP & VISUALIZATION (RED CONTROLS)\n",
    "# ==========================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\n",
    "n_neighbors = min(15, len(wells) - 1)\n",
    "reducer = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "\n",
    "# Create color palette: all Treatments are 'turbo', but CONTROL_NAME is 'red'\n",
    "unique_treats = wells[\"Treatment\"].unique()\n",
    "palette = sns.color_palette(\"turbo\", n_colors=len(unique_treats))\n",
    "color_map = dict(zip(unique_treats, palette))\n",
    "color_map[CONTROL_NAME] = \"red\" \n",
    "\n",
    "# Plot 1: Non-Sphered\n",
    "print(\"Running UMAP on Raw data...\")\n",
    "emb_raw = reducer.fit_transform(X_raw_scaled)\n",
    "sns.scatterplot(x=emb_raw[:, 0], y=emb_raw[:, 1], hue=wells[\"Treatment\"], \n",
    "                palette=color_map, style=(wells[\"Treatment\"] == CONTROL_NAME), \n",
    "                markers={True: \"X\", False: \"o\"}, s=180, ax=ax1, edgecolor='k')\n",
    "ax1.set_title(\"Well-Level: NO SPHERING (Red X = Control)\")\n",
    "\n",
    "# Plot 2: Sphered\n",
    "if X_sphered is not None:\n",
    "    print(\"Running UMAP on Sphered data...\")\n",
    "    emb_sph = reducer.fit_transform(X_sphered)\n",
    "    sns.scatterplot(x=emb_sph[:, 0], y=emb_sph[:, 1], hue=wells[\"Treatment\"], \n",
    "                    palette=color_map, style=(wells[\"Treatment\"] == CONTROL_NAME), \n",
    "                    markers={True: \"X\", False: \"o\"}, s=180, ax=ax2, edgecolor='k')\n",
    "    ax2.set_title(f\"Well-Level: SPHERED (Red X = Control)\")\n",
    "\n",
    "# Legend Handling\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax2.get_legend().remove() # Redundant legend\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb985798",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc67940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS & CONFIG (Windows Style)\n",
    "# ==========================================\n",
    "# Using 'r' before the string prevents \"invalid escape sequence\" errors on Windows\n",
    "PROJECT_ROOT = r\"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "REG_PARAM = 1e-2\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL DATA LOADING\n",
    "# ==========================================\n",
    "print(\"Loading Metadata...\")\n",
    "if not os.path.exists(METADATA_PATH):\n",
    "    raise FileNotFoundError(f\"Metadata not found at {METADATA_PATH}\")\n",
    "\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data = []\n",
    "site_level_features = []\n",
    "\n",
    "print(f\"Loading features from: {FEATURES_BASE}\")\n",
    "for i in tqdm(meta.index, desc=\"Processing Sites\"):\n",
    "    filename = os.path.join(\n",
    "        FEATURES_BASE,\n",
    "        str(meta.loc[i, \"Metadata_Plate\"]),\n",
    "        str(meta.loc[i, \"Metadata_Well\"]),\n",
    "        f\"{meta.loc[i, 'Metadata_Site']}.npz\"\n",
    "    )\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    # AGGREGATION 1: Site-level Median\n",
    "                    site_median = np.median(cells_f, axis=0)\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(site_median)\n",
    "        except: continue\n",
    "\n",
    "# Create DataFrame\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "\n",
    "# ==========================================\n",
    "# 3. WELL-LEVEL AGGREGATION (MEAN)\n",
    "# ==========================================\n",
    "# This allows us to see individual dots for each well\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "print(f\"Done. Found {len(wells)} unique wells.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. SPHERING (ZCA WHITENING)\n",
    "# ==========================================\n",
    "def perform_sphering(df, ctrl_label, reg):\n",
    "    ctrl_wells = df[df[\"Treatment\"] == ctrl_label][feature_cols].values\n",
    "    if len(ctrl_wells) < 2:\n",
    "        print(\"Warning: Need at least 2 control wells for sphering.\")\n",
    "        return None\n",
    "    \n",
    "    mean_vec = np.mean(ctrl_wells, axis=0)\n",
    "    X_centered = df[feature_cols].values - mean_vec\n",
    "    \n",
    "    # Calculate ZCA Matrix\n",
    "    cov = np.dot((ctrl_wells - mean_vec).T, (ctrl_wells - mean_vec)) / (len(ctrl_wells) - 1)\n",
    "    evals, evecs = np.linalg.eigh(cov + reg * np.eye(cov.shape[0]))\n",
    "    zca_matrix = np.dot(evecs, np.dot(np.diag(1.0 / np.sqrt(evals + 1e-6)), evecs.T))\n",
    "    \n",
    "    return np.dot(X_centered, zca_matrix.T)\n",
    "\n",
    "X_raw_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "X_sphered = perform_sphering(wells, CONTROL_NAME, REG_PARAM)\n",
    "\n",
    "# ==========================================\n",
    "# 5. UMAP & INTERACTIVE PLOTLY VISUALIZATION\n",
    "# ==========================================\n",
    "print(\"Running UMAP dimensionality reduction...\")\n",
    "n_neighbors = min(15, len(wells) - 1)\n",
    "reducer = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "\n",
    "emb_raw = reducer.fit_transform(X_raw_scaled)\n",
    "emb_sph = reducer.fit_transform(X_sphered) if X_sphered is not None else None\n",
    "\n",
    "# Build the interactive figure\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, \n",
    "    subplot_titles=(\"Raw (Standardized)\", f\"Sphered (Centered on {CONTROL_NAME})\")\n",
    ")\n",
    "\n",
    "def add_traces(fig, coords, col_idx):\n",
    "    temp_df = wells[[\"Well_ID\", \"Treatment\"]].copy()\n",
    "    temp_df[\"x\"] = coords[:, 0]\n",
    "    temp_df[\"y\"] = coords[:, 1]\n",
    "    \n",
    "    # Mutants: Black dots\n",
    "    mutants = temp_df[temp_df[\"Treatment\"] != CONTROL_NAME]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=mutants[\"x\"], y=mutants[\"y\"],\n",
    "        mode='markers', name='Mutant',\n",
    "        marker=dict(color='black', size=7, opacity=0.6),\n",
    "        text=[f\"Mutant: {t}<br>Well: {w}\" for t, w in zip(mutants[\"Treatment\"], mutants[\"Well_ID\"])],\n",
    "        hoverinfo='text'\n",
    "    ), row=1, col=col_idx)\n",
    "\n",
    "    # Controls: Red X's\n",
    "    controls = temp_df[temp_df[\"Treatment\"] == CONTROL_NAME]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=controls[\"x\"], y=controls[\"y\"],\n",
    "        mode='markers', name='Control',\n",
    "        marker=dict(color='red', size=10, symbol='x', line=dict(width=2)),\n",
    "        text=[f\"CONTROL: {t}<br>Well: {w}\" for t, w in zip(controls[\"Treatment\"], controls[\"Well_ID\"])],\n",
    "        hoverinfo='text'\n",
    "    ), row=1, col=col_idx)\n",
    "\n",
    "add_traces(fig, emb_raw, 1)\n",
    "if emb_sph is not None:\n",
    "    add_traces(fig, emb_sph, 2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Interactive Mutant Analysis: Hover to Identify Wells\",\n",
    "    template=\"plotly_white\",\n",
    "    height=600, width=1200,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Optional: Uncomment the line below to save this as a file you can open in a browser\n",
    "# fig.write_html(\"Mutant_UMAP_Interactive.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zonder hierarcy, gwn mean direct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ... (SETUP PATHS - SAME AS YOURS) ...\n",
    "PROJECT_ROOT = r\"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "REG_PARAM = 1e-2\n",
    "\n",
    "# ==========================================\n",
    "# 2. WHOLE-WELL AGGREGATION (DIRECT)\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "# We use a dictionary to group cells by Well_ID before averaging\n",
    "well_accumulator = {} \n",
    "\n",
    "print(\"Collecting all cells for whole-well aggregation...\")\n",
    "for i in tqdm(meta.index, desc=\"Reading Files\"):\n",
    "    well_id = f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "    treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "    \n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    if well_id not in well_accumulator:\n",
    "                        well_accumulator[well_id] = {'features': [], 'treatment': treatment}\n",
    "                    # Add all cells from this site to the well's list\n",
    "                    well_accumulator[well_id]['features'].append(cells_f)\n",
    "        except: continue\n",
    "\n",
    "# Now, calculate the mean for each well across ALL its cells\n",
    "well_level_data = []\n",
    "for well_id, content in tqdm(well_accumulator.items(), desc=\"Calculating Well Means\"):\n",
    "    # Stack all sites' cells into one big array for this well\n",
    "    all_cells_in_well = np.vstack(content['features'])\n",
    "    well_mean = np.mean(all_cells_in_well, axis=0)\n",
    "    \n",
    "    well_dict = {\"Well_ID\": well_id, \"Treatment\": content['treatment']}\n",
    "    # Add features as columns\n",
    "    for idx, val in enumerate(well_mean):\n",
    "        well_dict[idx] = val\n",
    "    well_level_data.append(well_dict)\n",
    "\n",
    "wells = pd.DataFrame(well_level_data)\n",
    "feature_cols = [i for i in range(all_cells_in_well.shape[1])]\n",
    "\n",
    "print(f\"Done. Aggregated {len(wells)} wells directly from cell populations.\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. SPHERING & UMAP (SAME AS YOUR CODE)\n",
    "# ==========================================\n",
    "# ... [Insert your perform_sphering function here] ...\n",
    "\n",
    "X_raw_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "X_sphered = perform_sphering(wells, CONTROL_NAME, REG_PARAM)\n",
    "\n",
    "# ... [Insert your Plotly code here] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff664a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "def perform_sphering(df, ctrl_label, reg):\n",
    "    ctrl_wells = df[df[\"Treatment\"] == ctrl_label][feature_cols].values\n",
    "    if len(ctrl_wells) < 2:\n",
    "        print(\"Warning: Need at least 2 control wells for sphering.\")\n",
    "        return None\n",
    "    \n",
    "    mean_vec = np.mean(ctrl_wells, axis=0)\n",
    "    X_centered = df[feature_cols].values - mean_vec\n",
    "    \n",
    "    # Calculate ZCA Matrix\n",
    "    cov = np.dot((ctrl_wells - mean_vec).T, (ctrl_wells - mean_vec)) / (len(ctrl_wells) - 1)\n",
    "    evals, evecs = np.linalg.eigh(cov + reg * np.eye(cov.shape[0]))\n",
    "    zca_matrix = np.dot(evecs, np.dot(np.diag(1.0 / np.sqrt(evals + 1e-6)), evecs.T))\n",
    "    \n",
    "    return np.dot(X_centered, zca_matrix.T)\n",
    "X_sphered = perform_sphering(wells, CONTROL_NAME, REG_PARAM)\n",
    "\n",
    "# 5. UMAP & INTERACTIVE PLOTLY VISUALIZATION\n",
    "# ==========================================\n",
    "print(\"Running UMAP dimensionality reduction...\")\n",
    "n_neighbors = min(15, len(wells) - 1)\n",
    "reducer = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "\n",
    "emb_raw = reducer.fit_transform(X_raw_scaled)\n",
    "emb_sph = reducer.fit_transform(X_sphered) if X_sphered is not None else None\n",
    "\n",
    "# Build the interactive figure\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, \n",
    "    subplot_titles=(\"Raw (Standardized)\", f\"Sphered (Centered on {CONTROL_NAME})\")\n",
    ")\n",
    "\n",
    "def add_traces(fig, coords, col_idx):\n",
    "    temp_df = wells[[\"Well_ID\", \"Treatment\"]].copy()\n",
    "    temp_df[\"x\"] = coords[:, 0]\n",
    "    temp_df[\"y\"] = coords[:, 1]\n",
    "    \n",
    "    # Mutants: Black dots\n",
    "    mutants = temp_df[temp_df[\"Treatment\"] != CONTROL_NAME]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=mutants[\"x\"], y=mutants[\"y\"],\n",
    "        mode='markers', name='Mutant',\n",
    "        marker=dict(color='black', size=7, opacity=0.6),\n",
    "        text=[f\"Mutant: {t}<br>Well: {w}\" for t, w in zip(mutants[\"Treatment\"], mutants[\"Well_ID\"])],\n",
    "        hoverinfo='text'\n",
    "    ), row=1, col=col_idx)\n",
    "\n",
    "    # Controls: Red X's\n",
    "    controls = temp_df[temp_df[\"Treatment\"] == CONTROL_NAME]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=controls[\"x\"], y=controls[\"y\"],\n",
    "        mode='markers', name='Control',\n",
    "        marker=dict(color='red', size=10, symbol='x', line=dict(width=2)),\n",
    "        text=[f\"CONTROL: {t}<br>Well: {w}\" for t, w in zip(controls[\"Treatment\"], controls[\"Well_ID\"])],\n",
    "        hoverinfo='text'\n",
    "    ), row=1, col=col_idx)\n",
    "\n",
    "add_traces(fig, emb_raw, 1)\n",
    "if emb_sph is not None:\n",
    "    add_traces(fig, emb_sph, 2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Interactive Mutant Analysis: Hover to Identify Wells\",\n",
    "    template=\"plotly_white\",\n",
    "    height=600, width=1200,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install adjustText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d46880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "#PROJECT_ROOT = r\"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\"\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49863e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ed9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# DeepProfiler Specs\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280 # 6400 / 5\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Voorbereiden van de DataFrame\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "\n",
    "# Aggregatie naar Well-level\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION & MULTI-PLOT\n",
    "# ==========================================\n",
    "# Definieer de plot configuraties\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels Together\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1 Only\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2 Only\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3 Only\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4 Only\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5 Only\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# Maak een grid van 2 rijen x 3 kolommen\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP: {config['name']}...\")\n",
    "    \n",
    "    # Selectie en Schalen\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # UMAP berekening\n",
    "    reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # Splitsen voor visualisatie\n",
    "    is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "    controls = embedding[is_control]\n",
    "    mutants = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "    \n",
    "    # Plotten van de punten\n",
    "    ax.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=100, label='Control', zorder=3)\n",
    "    ax.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=40, alpha=0.6, label='Mutants', zorder=2)\n",
    "    \n",
    "    # Labels toevoegen\n",
    "    texts = []\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutants[i, 0], mutants[i, 1], name, fontsize=8))\n",
    "    \n",
    "    # Adjust text zorgt dat labels niet overlappen per subplot\n",
    "    adjust_text(texts, ax=ax, only_move={'points':'y', 'text':'xy'}, \n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=0.5))\n",
    "    \n",
    "    ax.set_title(config['name'], fontsize=14, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "plt.suptitle(f\"Channel-specific UMAP Comparison ({len(wells)} Wells)\", fontsize=22, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS\n",
    "# ==========================================\n",
    "#PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project (Copy)\"\n",
    "PROJECT_ROOT =r\"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# DeepProfiler Specs\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280 \n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Prepare DataFrame\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "\n",
    "# Aggregate to Well-level\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION & MULTI-PLOT\n",
    "# ==========================================\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels Together\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1 Only\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2 Only\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3 Only\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4 Only\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5 Only\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP: {config['name']}...\")\n",
    "    \n",
    "    # --- CRITICAL FIXES FOR CONSISTENCY ---\n",
    "    # 1. Reset the global seed before EVERY UMAP run\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 2. Subset and Scale\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # 3. UMAP with explicit initialization\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=15, \n",
    "        random_state=42, \n",
    "        init='spectral', # Stable initialization\n",
    "        low_memory=False\n",
    "    )\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    # --------------------------------------\n",
    "\n",
    "    is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "    controls = embedding[is_control]\n",
    "    mutants = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "    \n",
    "    # Plotting\n",
    "    ax.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=100, label='Control', zorder=3)\n",
    "    ax.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=40, alpha=0.6, label='Mutants', zorder=2)\n",
    "    \n",
    "    texts = []\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutants[i, 0], mutants[i, 1], name, fontsize=8))\n",
    "    \n",
    "    adjust_text(texts, ax=ax, only_move={'points':'y', 'text':'xy'}, \n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=0.5))\n",
    "    \n",
    "    ax.set_title(config['name'], fontsize=14, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Force the aspect ratio to be equal so the shapes aren't stretched\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "plt.suptitle(f\"Channel-specific UMAP Comparison ({len(wells)} Wells)\", fontsize=22, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = r\"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Aggregating sites to well-level...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP - TUNED FOR BETTER CLUSTERING\n",
    "# ==========================================\n",
    "X_subset = wells[feature_cols].values\n",
    "X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "\n",
    "# We use 'random' init instead of 'spectral' because 'random' often \n",
    "# allows for the more \"stretched\" clusters you preferred in the 2nd code.\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15, \n",
    "    min_dist=0.1,    # Allows tighter clusters\n",
    "    random_state=42, \n",
    "    init='random',   \n",
    "    n_epochs=500     # More iterations for better convergence\n",
    ")\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING (Wide Aspect Ratio)\n",
    "# ==========================================\n",
    "# Making the plot wider (16x9) mimics the layout of the subplots you liked\n",
    "plt.figure(figsize=(16, 9))\n",
    "ax = plt.gca()\n",
    "\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=10))\n",
    "\n",
    "# adjust_text tuned for high-density labels\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'xy'},\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5))\n",
    "\n",
    "plt.title(f\"Optimized UMAP: All Channels Together\", fontsize=16, fontweight='bold')\n",
    "plt.gca().set_facecolor('#fafafa')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dab378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channels kiezen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & CONFIGURATION\n",
    "# ==========================================\n",
    "# Paden (Windows Raw String)\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# Kanaal configuratie\n",
    "CHANNELS_TO_KEEP = [1]  # Verander dit naar de kanalen die je wilt zien\n",
    "FEATS_PER_CHANNEL = 1280      # 6400 features / 5 kanalen\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "def get_channel_indices(channels, feats_per_ch):\n",
    "    indices = []\n",
    "    for ch in channels:\n",
    "        start = (ch - 1) * feats_per_ch\n",
    "        end = ch * feats_per_ch\n",
    "        indices.extend(range(start, end))\n",
    "    return indices\n",
    "\n",
    "selected_indices = get_channel_indices(CHANNELS_TO_KEEP, FEATS_PER_CHANNEL)\n",
    "\n",
    "print(f\"Loading Sites and selecting features for channels {CHANNELS_TO_KEEP}...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                # Verwijder cellen met NaNs\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    # Bereken median feature vector voor deze site\n",
    "                    site_median = np.median(cells_f, axis=0)\n",
    "                    \n",
    "                    # Filter direct op de gewenste kanalen om geheugen te besparen\n",
    "                    filtered_median = site_median[selected_indices]\n",
    "                    \n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(filtered_median)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Maak DataFrames\n",
    "feature_cols = [f\"feat_{i}\" for i in selected_indices]\n",
    "sites_df = pd.concat([\n",
    "    pd.DataFrame(site_level_data), \n",
    "    pd.DataFrame(site_level_features, columns=feature_cols)\n",
    "], axis=1)\n",
    "\n",
    "# Aggregeer naar Well-level (gemiddelde van de sites)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(f\"Running UMAP on {len(feature_cols)} features...\")\n",
    "X_raw = wells[feature_cols].values\n",
    "X_scaled = StandardScaler().fit_transform(X_raw)\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Splits data voor styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Teken de punten\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=150, \n",
    "            label=f'Control ({CONTROL_NAME})', zorder=3, linewidths=2)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=80, \n",
    "            alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Voeg labels toe\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=10))\n",
    "\n",
    "print(\"Adjusting labels for readability...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'xy'}, \n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.7, 1.7))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP (Channels: {CHANNELS_TO_KEEP})\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\", fontsize=12)\n",
    "plt.ylabel(\"UMAP 2\", fontsize=12)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.gca().set_facecolor('#fafafa')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channels kiezen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & CONFIGURATION\n",
    "# ==========================================\n",
    "# Paden (Windows Raw String)\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# Kanaal configuratie\n",
    "CHANNELS_TO_KEEP = [1,2,4,5]  # Verander dit naar de kanalen die je wilt zien\n",
    "FEATS_PER_CHANNEL = 1280      # 6400 features / 5 kanalen\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "def get_channel_indices(channels, feats_per_ch):\n",
    "    indices = []\n",
    "    for ch in channels:\n",
    "        start = (ch - 1) * feats_per_ch\n",
    "        end = ch * feats_per_ch\n",
    "        indices.extend(range(start, end))\n",
    "    return indices\n",
    "\n",
    "selected_indices = get_channel_indices(CHANNELS_TO_KEEP, FEATS_PER_CHANNEL)\n",
    "\n",
    "print(f\"Loading Sites and selecting features for channels {CHANNELS_TO_KEEP}...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                # Verwijder cellen met NaNs\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    # Bereken median feature vector voor deze site\n",
    "                    site_median = np.median(cells_f, axis=0)\n",
    "                    \n",
    "                    # Filter direct op de gewenste kanalen om geheugen te besparen\n",
    "                    filtered_median = site_median[selected_indices]\n",
    "                    \n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(filtered_median)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Maak DataFrames\n",
    "feature_cols = [f\"feat_{i}\" for i in selected_indices]\n",
    "sites_df = pd.concat([\n",
    "    pd.DataFrame(site_level_data), \n",
    "    pd.DataFrame(site_level_features, columns=feature_cols)\n",
    "], axis=1)\n",
    "\n",
    "# Aggregeer naar Well-level (gemiddelde van de sites)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(f\"Running UMAP on {len(feature_cols)} features...\")\n",
    "X_raw = wells[feature_cols].values\n",
    "X_scaled = StandardScaler().fit_transform(X_raw)\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Splits data voor styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Teken de punten\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=150, \n",
    "            label=f'Control ({CONTROL_NAME})', zorder=3, linewidths=2)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=80, \n",
    "            alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Voeg labels toe\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=10))\n",
    "\n",
    "print(\"Adjusting labels for readability...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'xy'}, \n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.7, 1.7))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP (Channels: {CHANNELS_TO_KEEP})\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\", fontsize=12)\n",
    "plt.ylabel(\"UMAP 2\", fontsize=12)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.gca().set_facecolor('#fafafa')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channels kiezen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & CONFIGURATION\n",
    "# ==========================================\n",
    "# Paden (Windows Raw String)\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project (Copy)\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# Kanaal configuratie\n",
    "CHANNELS_TO_KEEP = [5]  # Verander dit naar de kanalen die je wilt zien\n",
    "FEATS_PER_CHANNEL = 1280      # 6400 features / 5 kanalen\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "def get_channel_indices(channels, feats_per_ch):\n",
    "    indices = []\n",
    "    for ch in channels:\n",
    "        start = (ch - 1) * feats_per_ch\n",
    "        end = ch * feats_per_ch\n",
    "        indices.extend(range(start, end))\n",
    "    return indices\n",
    "\n",
    "selected_indices = get_channel_indices(CHANNELS_TO_KEEP, FEATS_PER_CHANNEL)\n",
    "\n",
    "print(f\"Loading Sites and selecting features for channels {CHANNELS_TO_KEEP}...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                # Verwijder cellen met NaNs\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    # Bereken median feature vector voor deze site\n",
    "                    site_median = np.median(cells_f, axis=0)\n",
    "                    \n",
    "                    # Filter direct op de gewenste kanalen om geheugen te besparen\n",
    "                    filtered_median = site_median[selected_indices]\n",
    "                    \n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(filtered_median)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Maak DataFrames\n",
    "feature_cols = [f\"feat_{i}\" for i in selected_indices]\n",
    "sites_df = pd.concat([\n",
    "    pd.DataFrame(site_level_data), \n",
    "    pd.DataFrame(site_level_features, columns=feature_cols)\n",
    "], axis=1)\n",
    "\n",
    "# Aggregeer naar Well-level (gemiddelde van de sites)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(f\"Running UMAP on {len(feature_cols)} features...\")\n",
    "X_raw = wells[feature_cols].values\n",
    "X_scaled = StandardScaler().fit_transform(X_raw)\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Splits data voor styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Teken de punten\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=150, \n",
    "            label=f'Control ({CONTROL_NAME})', zorder=3, linewidths=2)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=80, \n",
    "            alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Voeg labels toe\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=10))\n",
    "\n",
    "print(\"Adjusting labels for readability...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'xy'}, \n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.7, 1.7))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP (Channels: {CHANNELS_TO_KEEP})\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\", fontsize=12)\n",
    "plt.ylabel(\"UMAP 2\", fontsize=12)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.gca().set_facecolor('#fafafa')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d088d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace with the path to one of your files\n",
    "file_path = r\"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\\outputs\\results\\features\\PLATE1_T2\\A1\\1.npz\"\n",
    "\n",
    "# Load the file\n",
    "with np.load(file_path) as data:\n",
    "    # 1. See the 'keys' (the names of the arrays inside)\n",
    "    print(\"Keys in this file:\", data.files)\n",
    "    \n",
    "    # 2. Extract the features\n",
    "    features = data['features']\n",
    "    \n",
    "    # 3. Check the dimensions\n",
    "    # Shape will be (Number of Cells, Number of Features)\n",
    "    print(\"Array Shape:\", features.shape)\n",
    "    \n",
    "    # 4. Look at a small slice of the data (first 5 cells, first 5 features)\n",
    "    print(\"Data Preview:\\n\", features[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc5660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = r\"E:\\groteEdeepprofilerdingen\\deepprofileroutputsetc\\my_dp_project (Copy)\\outputs\\results\\features\\PLATE1_T2\\A1\\0.npz\"\n",
    "\n",
    "with np.load(file_path) as data:\n",
    "    # Convert the numpy array to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data['features'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(\"site_features_preview2.csv\", index=False)\n",
    "    print(\"Saved to site_features_preview.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metmasking_length\n",
    "import numpy as np\n",
    "\n",
    "# Replace with the path to one of your files\n",
    "file_path = \"/media/arnout/Elements1/Thesis/project_masking_label/outputs/results/features/PLATE1_T2/A1/11.npz\"\n",
    "\n",
    "# Load the file\n",
    "with np.load(file_path) as data:\n",
    "    # 1. See the 'keys' (the names of the arrays inside)\n",
    "    print(\"Keys in this file:\", data.files)\n",
    "    \n",
    "    # 2. Extract the features\n",
    "    features = data['features']\n",
    "    \n",
    "    # 3. Check the dimensions\n",
    "    # Shape will be (Number of Cells, Number of Features)\n",
    "    print(\"Array Shape:\", features.shape)\n",
    "    \n",
    "    # 4. Look at a small slice of the data (first 5 cells, first 5 features)\n",
    "    print(\"Data Preview:\\n\", features[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318125af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS & CONFIG\n",
    "# ==========================================\n",
    "# Update these to match your exact drive location\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/Thesis/my_dp_project (Copy)/\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs/results/features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs/metadata/index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "REG_PARAM = 1e-2 # Regularization parameter for ZCA\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL DATA LOADING\n",
    "# ==========================================\n",
    "if not os.path.exists(METADATA_PATH):\n",
    "    raise FileNotFoundError(f\"Could not find index.csv at {METADATA_PATH}\")\n",
    "\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data = []\n",
    "site_level_features = []\n",
    "\n",
    "print(f\"Loading data from: {FEATURES_BASE}\")\n",
    "for i in tqdm(meta.index, desc=\"Sites Loaded\"):\n",
    "    # Path construction: Root/Plate/Well/Site.npz\n",
    "    filename = os.path.join(\n",
    "        FEATURES_BASE,\n",
    "        str(meta.loc[i, \"Metadata_Plate\"]),\n",
    "        str(meta.loc[i, \"Metadata_Well\"]),\n",
    "        f\"{meta.loc[i, 'Metadata_Site']}.npz\"\n",
    "    )\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                # Filter out NaNs\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    # AGGREGATION LEVEL 1: Site-level Median\n",
    "                    site_median = np.median(cells_f, axis=0)\n",
    "                    \n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(site_median)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Create Main DataFrame\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "\n",
    "# ==========================================\n",
    "# 3. AGGREGATION LEVEL 2: Well-level Mean\n",
    "# ==========================================\n",
    "# We keep wells individual so we can see the 'no_sgRNA' consistency check\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "print(f\"\\nProcessing complete. Found {len(wells)} unique wells.\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. SPHERING (ZCA WHITENING) LOGIC\n",
    "# ==========================================\n",
    "def perform_sphering(df, ctrl_label, reg):\n",
    "    # Extract control well features\n",
    "    ctrl_wells = df[df[\"Treatment\"] == ctrl_label][feature_cols].values\n",
    "    if len(ctrl_wells) < 2:\n",
    "        print(f\"Warning: Not enough {ctrl_label} wells for covariance calculation.\")\n",
    "        return None\n",
    "    \n",
    "    # Center the entire dataset based on control mean\n",
    "    mean_vec = np.mean(ctrl_wells, axis=0)\n",
    "    X_centered = df[feature_cols].values - mean_vec\n",
    "    \n",
    "    # Calculate ZCA Matrix on control wells\n",
    "    ctrl_centered = ctrl_wells - mean_vec\n",
    "    cov = np.dot(ctrl_centered.T, ctrl_centered) / (len(ctrl_wells) - 1)\n",
    "    evals, evecs = np.linalg.eigh(cov + reg * np.eye(cov.shape[0]))\n",
    "    zca_matrix = np.dot(evecs, np.dot(np.diag(1.0 / np.sqrt(evals + 1e-6)), evecs.T))\n",
    "    \n",
    "    # Transform all data\n",
    "    return np.dot(X_centered, zca_matrix.T)\n",
    "\n",
    "# Prepare both datasets\n",
    "X_raw_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "X_sphered = perform_sphering(wells, CONTROL_NAME, REG_PARAM)\n",
    "\n",
    "# ==========================================\n",
    "# 5. UMAP & VISUALIZATION\n",
    "# ==========================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n",
    "n_neighbors = min(15, len(wells) - 1)\n",
    "reducer = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "\n",
    "# Plot 1: Non-Sphered (Standardized Only)\n",
    "print(\"Computing UMAP for Raw features...\")\n",
    "emb_raw = reducer.fit_transform(X_raw_scaled)\n",
    "sns.scatterplot(x=emb_raw[:, 0], y=emb_raw[:, 1], hue=wells[\"Treatment\"], \n",
    "                style=(wells[\"Treatment\"] == CONTROL_NAME), markers={True: \"X\", False: \"o\"},\n",
    "                s=200, ax=ax1, palette=\"turbo\", alpha=0.8, edgecolor='w')\n",
    "ax1.set_title(\"WELL-LEVEL: No Sphering (Standardized)\\nChecking for technical plate effects\", fontsize=15)\n",
    "\n",
    "# Plot 2: Sphered\n",
    "if X_sphered is not None:\n",
    "    print(\"Computing UMAP for Sphered features...\")\n",
    "    emb_sph = reducer.fit_transform(X_sphered)\n",
    "    sns.scatterplot(x=emb_sph[:, 0], y=emb_sph[:, 1], hue=wells[\"Treatment\"], \n",
    "                    style=(wells[\"Treatment\"] == CONTROL_NAME), markers={True: \"X\", False: \"o\"},\n",
    "                    s=200, ax=ax2, palette=\"turbo\", alpha=0.8, edgecolor='w')\n",
    "    ax2.set_title(f\"WELL-LEVEL: Sphered (Aligned to {CONTROL_NAME})\\nControls (X) should cluster tightly\", fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################testje#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exact zoals vorige plaat gerund: illuminatin and compression on false, maar toch gebeuren illuminaison and compression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exact zoals vorige plaat gerund: illuminatin and compression on false, maar nu heb ik de illuminatin en compresison file andere naam gegeven: zelfde output dus ik denk dat bij vorige geen illum en compression is in rekening gebracht\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nu illumniaiton correction en compression: true, compresiso nen illumination files gnereeted EN nu worden ze ook gebruikt bij profiling\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21711f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wel illumination correction (true), geen compression (false)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f831f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nog eens illumination corretction: ipv: calculate: true gwn deze zin wegdoen zoals in de voorbeeld files, geen compression\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geen illuminationcorr en geen compression (files echt gedeleted)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab78391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset_masking\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def get_aggregated_features(metadata_df, features_root):\n",
    "    \"\"\"\n",
    "    Loads .npz files for each site, calculates the mean \n",
    "    (well-level or treatment-level) and returns a feature matrix.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in metadata_df.iterrows():\n",
    "        # Construct the path to the .npz file\n",
    "        # DeepProfiler structure: outputs/features/<Plate>/<Well>_<Site>.npz\n",
    "        plate = str(row['Metadata_Plate'])\n",
    "        well = str(row['Metadata_Well'])\n",
    "        site = str(row['Metadata_Site'])\n",
    "        \n",
    "        feat_path = os.path.join(features_root, plate, well, f\"{site}.npz\")\n",
    "        \n",
    "        if os.path.exists(feat_path):\n",
    "            # Load .npz file\n",
    "            data = np.load(feat_path)\n",
    "            # 'features' is the standard key used by DeepProfiler\n",
    "            feats = data['features'] \n",
    "            \n",
    "            # Take the mean of all cells in this site to get the 'Site Centroid'\n",
    "            site_mean = np.mean(feats, axis=0)\n",
    "            \n",
    "            all_features.append(site_mean)\n",
    "            labels.append(row['Treatment'])\n",
    "        else:\n",
    "            print(f\"Warning: Feature file not found: {feat_path}\")\n",
    "\n",
    "    return pd.DataFrame(all_features), labels\n",
    "\n",
    "# 1. Load your main metadata (the index.csv you showed)\n",
    "metadata = pd.read_csv(\"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset/inputs/metadata/index.csv\")\n",
    "\n",
    "# 2. Set your output directories\n",
    "# (Adjust these to where your profiling outputs are stored)\n",
    "output_no_mask = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset/outputs/results /features\"\n",
    "output_with_mask = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset_masking/outputs/results/features\"\n",
    "\n",
    "# 3. Define the two mutants you want to compare\n",
    "mutant_1 = \"trnH\" # Replace with your actual treatment name\n",
    "mutant_2 = \"dnaG\" # Replace with your actual treatment name\n",
    "\n",
    "def calculate_mutant_dist(feat_dir, meta_df, m1, m2):\n",
    "    # Load and aggregate\n",
    "    df_feats, labels = get_aggregated_features(meta_df, feat_dir)\n",
    "    df_feats['Treatment'] = labels\n",
    "    \n",
    "    # Calculate Centroids for the specific mutants\n",
    "    centroid1 = df_feats[df_feats['Treatment'] == m1].drop('Treatment', axis=1).mean()\n",
    "    centroid2 = df_feats[df_feats['Treatment'] == m2].drop('Treatment', axis=1).mean()\n",
    "    \n",
    "    return euclidean(centroid1, centroid2)\n",
    "\n",
    "# 4. Perform Calculation\n",
    "print(\"Calculating distances...\")\n",
    "dist_no_mask = calculate_mutant_dist(output_no_mask, metadata, mutant_1, mutant_2)\n",
    "dist_mask = calculate_mutant_dist(output_with_mask, metadata, mutant_1, mutant_2)\n",
    "\n",
    "# 5. Output Results\n",
    "print(f\"\\nResults for separation between {mutant_1} and {mutant_2}:\")\n",
    "print(f\"--- Distance (No Mask):   {dist_no_mask:.4f}\")\n",
    "print(f\"--- Distance (With Mask): {dist_mask:.4f}\")\n",
    "\n",
    "change = ((dist_mask - dist_no_mask) / dist_no_mask) * 100\n",
    "print(f\"--- Difference: {change:+.2f}%\")\n",
    "\n",
    "if change > 0:\n",
    "    print(\"Interpretation: Masking increased the separation between these mutants.\")\n",
    "else:\n",
    "    print(\"Interpretation: Masking reduced the separation (context might be important).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6613ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset_masking\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a39be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alles_met_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # Ensures labels don't overlap\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS (Windows Raw String)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project_masking\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Flatten to Well-Level\n",
    "num_features = site_level_features[0].shape[0]\n",
    "feature_cols = [i for i in range(num_features)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP REDUCTION\n",
    "# ==========================================\n",
    "print(\"Running UMAP...\")\n",
    "X_scaled = StandardScaler().fit_transform(wells[feature_cols].values)\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(X_scaled)\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLOTTING WITH SMART LABELS\n",
    "# ==========================================\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Separate for styling\n",
    "is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "controls = embedding[is_control]\n",
    "mutants = embedding[~is_control]\n",
    "mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "\n",
    "# Plot dots\n",
    "plt.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=3)\n",
    "plt.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=60, alpha=0.6, label='Mutants', zorder=2)\n",
    "\n",
    "# Create labels list\n",
    "texts = []\n",
    "for i, name in enumerate(mutant_names):\n",
    "    # Only label if it's not the control\n",
    "    texts.append(plt.text(mutants[i, 0], mutants[i, 1], name, fontsize=9, fontweight='medium'))\n",
    "\n",
    "# Use adjust_text to repel labels from each other and the dots\n",
    "print(\"Adjusting labels (this may take a few seconds)...\")\n",
    "adjust_text(texts, \n",
    "            only_move={'points':'y', 'text':'y'}, # Encourages horizontal reading\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "            expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.title(f\"Well-Level UMAP: {len(wells)} Total Wells\", fontsize=16)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.gca().set_facecolor('#fafafa') # Slight grey background for contrast\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a030bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/my_dp_project_masking\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Data voorbereiden\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING LOOP\n",
    "# ==========================================\n",
    "# Definieer de subsets die we willen plotten\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# Maak een grid van 2 rijen x 3 kolommen\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # Selecteer data voor deze specifieke subset\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # Run UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # Data splitsen voor visualisatie\n",
    "    is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "    controls = embedding[is_control]\n",
    "    mutants = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "    \n",
    "    # Plotten\n",
    "    ax.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=100, label='Control', zorder=3)\n",
    "    ax.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=40, alpha=0.6, label='Mutants', zorder=2)\n",
    "    \n",
    "    # Labels toevoegen\n",
    "    texts = []\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutants[i, 0], mutants[i, 1], name, fontsize=8))\n",
    "    \n",
    "    adjust_text(texts, ax=ax, only_move={'points':'y', 'text':'xy'}, expand_points=(1.2, 1.2))\n",
    "    \n",
    "    ax.set_title(f\"{config['name']}\", fontsize=14, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "plt.suptitle(f\"Channel Comparison UMAP - {len(wells)} Wells\", fontsize=20, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c36864",
   "metadata": {},
   "outputs": [],
   "source": [
    "######aggregation and plotting seprate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/Thesis/my_dp_project_neighbours\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Data voorbereiden\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING LOOP\n",
    "# ==========================================\n",
    "# Definieer de subsets die we willen plotten\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# Maak een grid van 2 rijen x 3 kolommen\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # Selecteer data voor deze specifieke subset\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # Run UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # Data splitsen voor visualisatie\n",
    "    is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "    controls = embedding[is_control]\n",
    "    mutants = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "    \n",
    "    # Plotten\n",
    "    ax.scatter(controls[:, 0], controls[:, 1], c='red', marker='x', s=100, label='Control', zorder=3)\n",
    "    ax.scatter(mutants[:, 0], mutants[:, 1], c='black', marker='o', s=40, alpha=0.6, label='Mutants', zorder=2)\n",
    "    \n",
    "    # Labels toevoegen\n",
    "    texts = []\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutants[i, 0], mutants[i, 1], name, fontsize=8))\n",
    "    \n",
    "    adjust_text(texts, ax=ax, only_move={'points':'y', 'text':'xy'}, expand_points=(1.2, 1.2))\n",
    "    \n",
    "    ax.set_title(f\"{config['name']}\", fontsize=14, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "plt.suptitle(f\"Channel Comparison UMAP - {len(wells)} Wells\", fontsize=20, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676bbe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/Thesis/my_dp_project_neighbours\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "# ==========================================\n",
    "# 2. HIERARCHICAL LOADING & AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "site_level_data, site_level_features = [], []\n",
    "\n",
    "print(\"Loading and Aggregating Sites...\")\n",
    "for i in tqdm(meta.index):\n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                if len(cells_f) > 0:\n",
    "                    site_level_data.append({\n",
    "                        \"Well_ID\": f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\",\n",
    "                        \"Treatment\": str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "                    })\n",
    "                    site_level_features.append(np.median(cells_f, axis=0))\n",
    "        except: continue\n",
    "\n",
    "# Data voorbereiden\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "sites_df = pd.concat([pd.DataFrame(site_level_data), \n",
    "                      pd.DataFrame(site_level_features, columns=feature_cols)], axis=1)\n",
    "wells = sites_df.groupby([\"Well_ID\", \"Treatment\"])[feature_cols].median().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0467840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING LOOP\n",
    "# ==========================================\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # Preprocessing\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # Run UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # Split for plotting\n",
    "    is_control = wells[\"Treatment\"] == CONTROL_NAME\n",
    "    \n",
    "    # Plotting\n",
    "    ax.scatter(embedding[is_control, 0], embedding[is_control, 1], \n",
    "               c='red', marker='x', s=100, label='Control', zorder=3)\n",
    "    ax.scatter(embedding[~is_control, 0], embedding[~is_control, 1], \n",
    "               c='black', marker='o', s=40, alpha=0.6, label='Mutants', zorder=2)\n",
    "    \n",
    "    # Labels\n",
    "    mutant_names = wells[~is_control][\"Treatment\"].values\n",
    "    mutant_embeds = embedding[~is_control]\n",
    "    texts = [ax.text(mutant_embeds[i, 0], mutant_embeds[i, 1], name, fontsize=8) \n",
    "             for i, name in enumerate(mutant_names)]\n",
    "    \n",
    "    adjust_text(texts, ax=ax, only_move={'points':'y', 'text':'xy'}, expand_points=(1.2, 1.2))\n",
    "    \n",
    "    ax.set_title(f\"{config['name']}\", fontsize=14, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    if idx == 0: ax.legend(loc='upper left')\n",
    "\n",
    "plt.suptitle(f\"Channel Comparison UMAP - {len(wells)} Wells\", fontsize=20, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING (Full Standalone Cell)\n",
    "# ==========================================\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Ensure these match your aggregation cell variables\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# Define the channel subsets\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# Create Figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # 2. Run UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # 3. Split Data for Plotting\n",
    "    is_control = wells[TREATMENT_COL] == CONTROL_NAME\n",
    "    \n",
    "    # Extract Control data\n",
    "    ctrl_embed = embedding[is_control]\n",
    "    ctrl_well_ids = wells[is_control][\"Well_ID\"].values\n",
    "    \n",
    "    # Extract Mutant data\n",
    "    mutant_embed = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][TREATMENT_COL].values\n",
    "    \n",
    "    # 4. Draw Scatter Points\n",
    "    # Controls as Red Crosses\n",
    "    ax.scatter(ctrl_embed[:, 0], ctrl_embed[:, 1], \n",
    "               c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=4)\n",
    "    \n",
    "    # Mutants as Black Dots\n",
    "    ax.scatter(mutant_embed[:, 0], mutant_embed[:, 1], \n",
    "               c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "    \n",
    "    # 5. Create Labels (Texts)\n",
    "    texts = []\n",
    "    \n",
    "    # Add Red Well_ID labels for Controls\n",
    "    for i, well_id in enumerate(ctrl_well_ids):\n",
    "        texts.append(ax.text(ctrl_embed[i, 0], ctrl_embed[i, 1], \n",
    "                             well_id, fontsize=7, color='red', fontweight='bold'))\n",
    "    \n",
    "    # Add Black Treatment labels for Mutants\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutant_embed[i, 0], mutant_embed[i, 1], \n",
    "                             name, fontsize=8, color='black'))\n",
    "    \n",
    "    # 6. Adjust Labels to prevent overlaps\n",
    "    # arrowprops adds a subtle line from the text to the point if it moves\n",
    "    adjust_text(texts, ax=ax, \n",
    "                arrowprops=dict(arrowstyle='-', color='silver', lw=0.5),\n",
    "                only_move={'points':'y', 'text':'xy'}, \n",
    "                expand_points=(1.5, 1.5))\n",
    "    \n",
    "    # 7. Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', frameon=True, shadow=True)\n",
    "\n",
    "# Final global formatting\n",
    "plt.suptitle(f\"Channel Comparison UMAP - {len(wells)} Wells (Double Median Aggregation)\", \n",
    "             fontsize=22, y=1.02, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot (Optional)\n",
    "# plt.savefig(\"umap_channel_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ba40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median over alles\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/Thesis/my_dp_project_neighbours\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# ==========================================\n",
    "# 2. SINGLE-STEP WELL AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "# Dictionary to store all cells per well: { \"Well_ID\": [list_of_feature_arrays] }\n",
    "well_storage = {}\n",
    "# Dictionary to map Well_ID back to its Treatment name\n",
    "well_to_treatment = {}\n",
    "\n",
    "print(\"Loading cells and grouping by Well...\")\n",
    "for i in tqdm(meta.index):\n",
    "    well_id = f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "    treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "    \n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                # Clean NaNs\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    if well_id not in well_storage:\n",
    "                        well_storage[well_id] = []\n",
    "                        well_to_treatment[well_id] = treatment\n",
    "                    \n",
    "                    well_storage[well_id].append(cells_f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Now calculate the median for each well using all pooled cells\n",
    "well_level_data = []\n",
    "\n",
    "print(\"Calculating Single Median per Well...\")\n",
    "for well_id, feature_list in tqdm(well_storage.items()):\n",
    "    # Stack all cells from all sites into one large array for this well\n",
    "    all_cells_in_well = np.vstack(feature_list)\n",
    "    \n",
    "    # Calculate median across the 0-axis (rows/cells)\n",
    "    well_median = np.median(all_cells_in_well, axis=0)\n",
    "    \n",
    "    # Store result\n",
    "    row = {\"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "    for idx, val in enumerate(well_median):\n",
    "        row[idx] = val\n",
    "    well_level_data.append(row)\n",
    "\n",
    "wells = pd.DataFrame(well_level_data)\n",
    "\n",
    "print(f\"Aggregation complete. Processed {len(wells)} wells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING (Full Standalone Cell)\n",
    "# ==========================================\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Ensure these match your aggregation cell variables\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# Define the channel subsets\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))},\n",
    "    \n",
    "]\n",
    "\n",
    "# Create Figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # 2. Run UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # 3. Split Data for Plotting\n",
    "    is_control = wells[TREATMENT_COL] == CONTROL_NAME\n",
    "    \n",
    "    # Extract Control data\n",
    "    ctrl_embed = embedding[is_control]\n",
    "    ctrl_well_ids = wells[is_control][\"Well_ID\"].values\n",
    "    \n",
    "    # Extract Mutant data\n",
    "    mutant_embed = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][TREATMENT_COL].values\n",
    "    \n",
    "    # 4. Draw Scatter Points\n",
    "    # Controls as Red Crosses\n",
    "    ax.scatter(ctrl_embed[:, 0], ctrl_embed[:, 1], \n",
    "               c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=4)\n",
    "    \n",
    "    # Mutants as Black Dots\n",
    "    ax.scatter(mutant_embed[:, 0], mutant_embed[:, 1], \n",
    "               c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "    \n",
    "    # 5. Create Labels (Texts)\n",
    "    texts = []\n",
    "    \n",
    "    # Add Red Well_ID labels for Controls\n",
    "    for i, well_id in enumerate(ctrl_well_ids):\n",
    "        texts.append(ax.text(ctrl_embed[i, 0], ctrl_embed[i, 1], \n",
    "                             well_id, fontsize=7, color='red', fontweight='bold'))\n",
    "    \n",
    "    # Add Black Treatment labels for Mutants\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutant_embed[i, 0], mutant_embed[i, 1], \n",
    "                             name, fontsize=8, color='black'))\n",
    "    \n",
    "    # 6. Adjust Labels to prevent overlaps\n",
    "    # arrowprops adds a subtle line from the text to the point if it moves\n",
    "    adjust_text(texts, ax=ax, \n",
    "                arrowprops=dict(arrowstyle='-', color='silver', lw=0.5),\n",
    "                only_move={'points':'y', 'text':'xy'}, \n",
    "                expand_points=(1.5, 1.5))\n",
    "    \n",
    "    # 7. Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', frameon=True, shadow=True)\n",
    "\n",
    "# Final global formatting\n",
    "plt.suptitle(f\"Channel Comparison UMAP - {len(wells)} Wells (Double Median Aggregation)\", \n",
    "             fontsize=22, y=1.02, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot (Optional)\n",
    "# plt.savefig(\"umap_channel_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c85e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING (With Channel Combinations)\n",
    "# ==========================================\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "# Helper function to combine channel indices\n",
    "def get_ch_indices(channels):\n",
    "    \"\"\"\n",
    "    channels: list of integers (e.g., [1, 2, 5])\n",
    "    returns: flattened list of indices for those channels\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for ch in channels:\n",
    "        # Subtract 1 because list(range) is 0-indexed\n",
    "        start = (ch - 1) * FEATS_PER_CH\n",
    "        end = ch * FEATS_PER_CH\n",
    "        indices.extend(list(range(start, end)))\n",
    "    return indices\n",
    "\n",
    "# Define your subsets here - You can add any combination you like!\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": get_ch_indices([1, 2, 3, 4, 5])},\n",
    "    {\"name\": \"Channels 1, 2, 3, 5\", \"indices\": get_ch_indices([1, 2, 3, 5])},\n",
    "    {\"name\": \"Channel 1 only\", \"indices\": get_ch_indices([1])},\n",
    "    {\"name\": \"Channel 2 only\", \"indices\": get_ch_indices([2])},\n",
    "    {\"name\": \"Channel 3 only\", \"indices\": get_ch_indices([3])},\n",
    "    {\"name\": \"Channel 5 only\", \"indices\": get_ch_indices([5])}\n",
    "]\n",
    "\n",
    "# Adjust grid size based on the number of configs\n",
    "num_plots = len(plot_configs)\n",
    "cols = 3\n",
    "rows = (num_plots + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(26, 8 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    # Note: Use feature_cols if they are strings, but since they are integers from the aggregation cell:\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # 2. Run UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # 3. Split Data\n",
    "    is_control = wells[TREATMENT_COL] == CONTROL_NAME\n",
    "    ctrl_embed = embedding[is_control]\n",
    "    ctrl_well_ids = wells[is_control][\"Well_ID\"].values\n",
    "    mutant_embed = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][TREATMENT_COL].values\n",
    "    \n",
    "    # 4. Draw Scatter Points\n",
    "    ax.scatter(ctrl_embed[:, 0], ctrl_embed[:, 1], \n",
    "               c='red', marker='x', s=120, label='Control', zorder=4)\n",
    "    ax.scatter(mutant_embed[:, 0], mutant_embed[:, 1], \n",
    "               c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "    \n",
    "    # 5. Create Labels\n",
    "    texts = []\n",
    "    for i, well_id in enumerate(ctrl_well_ids):\n",
    "        texts.append(ax.text(ctrl_embed[i, 0], ctrl_embed[i, 1], \n",
    "                             well_id, fontsize=7, color='red', fontweight='bold'))\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutant_embed[i, 0], mutant_embed[i, 1], \n",
    "                             name, fontsize=8, color='black'))\n",
    "    \n",
    "    # 6. Adjust Labels\n",
    "    adjust_text(texts, ax=ax, \n",
    "                arrowprops=dict(arrowstyle='-', color='silver', lw=0.5),\n",
    "                only_move={'points':'y', 'text':'xy'}, \n",
    "                expand_points=(1.5, 1.5))\n",
    "    \n",
    "    # 7. Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left')\n",
    "\n",
    "# Hide unused subplots if plot_configs is not a multiple of 3\n",
    "for j in range(idx + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Channel Combination UMAP Comparison\", fontsize=22, y=1.01, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8698a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4acb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median over alles\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/Thesis/my_dp_project_neighbours\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# ==========================================\n",
    "# 2. SINGLE-STEP WELL AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "# Dictionary to store all cells per well: { \"Well_ID\": [list_of_feature_arrays] }\n",
    "well_storage = {}\n",
    "# Dictionary to map Well_ID back to its Treatment name\n",
    "well_to_treatment = {}\n",
    "\n",
    "print(\"Loading cells and grouping by Well...\")\n",
    "for i in tqdm(meta.index):\n",
    "    well_id = f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "    treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "    \n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                # Clean NaNs\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    if well_id not in well_storage:\n",
    "                        well_storage[well_id] = []\n",
    "                        well_to_treatment[well_id] = treatment\n",
    "                    \n",
    "                    well_storage[well_id].append(cells_f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Now calculate the median for each well using all pooled cells\n",
    "well_level_data = []\n",
    "\n",
    "print(\"Calculating Single Median per Well...\")\n",
    "for well_id, feature_list in tqdm(well_storage.items()):\n",
    "    # Stack all cells from all sites into one large array for this well\n",
    "    all_cells_in_well = np.vstack(feature_list)\n",
    "    \n",
    "    # Calculate median across the 0-axis (rows/cells)\n",
    "    well_median = np.median(all_cells_in_well, axis=0)\n",
    "    \n",
    "    # Store result\n",
    "    row = {\"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "    for idx, val in enumerate(well_median):\n",
    "        row[idx] = val\n",
    "    well_level_data.append(row)\n",
    "\n",
    "wells = pd.DataFrame(well_level_data)\n",
    "\n",
    "print(f\"Aggregation complete. Processed {len(wells)} wells.\")\n",
    "\n",
    "# Load your area report\n",
    "AREA_REPORT_PATH = \"/media/arnout/Elements1/Thesis/my_dp_project_neighbours/inputs/cell_area_report.csv\"\n",
    "area_df = pd.read_csv(AREA_REPORT_PATH)\n",
    "\n",
    "# Create the same Well_ID used in your features (Plate_Well)\n",
    "area_df[\"Well_ID\"] = area_df[\"Plate\"] + \"_\" + area_df[\"Well\"]\n",
    "\n",
    "# Calculate the average area per well\n",
    "well_areas = area_df.groupby(\"Well_ID\")[\"Area\"].median().reset_index()\n",
    "\n",
    "# Merge this area info into your 'wells' feature dataframe\n",
    "wells = wells.merge(well_areas, on=\"Well_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size color overlay\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ... [Keep your config and plot_configs as they were] ...\n",
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING (Full Standalone Cell)\n",
    "# ==========================================\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Ensure these match your aggregation cell variables\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# Define the channel subsets\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))},\n",
    "    \n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # Split Data\n",
    "    is_control = wells[TREATMENT_COL] == CONTROL_NAME\n",
    "    \n",
    "    # 1. Controls (Red Crosses - Area ignored for color to keep them distinct)\n",
    "    ctrl_embed = embedding[is_control]\n",
    "    ax.scatter(ctrl_embed[:, 0], ctrl_embed[:, 1], \n",
    "               c='red', marker='x', s=150, label='Control (no_sgRNA)', zorder=5)\n",
    "    \n",
    "    # 2. Mutants (Colored by Area)\n",
    "    mutant_embed = embedding[~is_control]\n",
    "    mutant_areas = wells[~is_control][\"Area\"].values\n",
    "    mutant_names = wells[~is_control][TREATMENT_COL].values\n",
    "\n",
    "    # We use a colormap like 'viridis' or 'plasma'\n",
    "    # 'vmax' and 'vmin' can be set to clip outliers if needed\n",
    "    sc = ax.scatter(mutant_embed[:, 0], mutant_embed[:, 1], \n",
    "                    c=mutant_areas, cmap='viridis', marker='o', \n",
    "                    s=80, alpha=0.8, edgecolors='white', lw=0.5, zorder=4)\n",
    "    \n",
    "    # 3. Add Labels\n",
    "    texts = []\n",
    "    # Controls\n",
    "    for i, well_id in enumerate(wells[is_control][\"Well_ID\"].values):\n",
    "        texts.append(ax.text(ctrl_embed[i, 0], ctrl_embed[i, 1], well_id, color='red', fontsize=8))\n",
    "    # Mutants\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutant_embed[i, 0], mutant_embed[i, 1], name, fontsize=8))\n",
    "\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='silver', lw=0.5))\n",
    "    \n",
    "    # 4. Colorbar (Only add once or to each subplot)\n",
    "    cbar = plt.colorbar(sc, ax=ax, shrink=0.6)\n",
    "    cbar.set_label('Median Cell Area (Pixels)', fontsize=10)\n",
    "\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f\"UMAP Colored by Cell Area - {len(wells)} Wells\", fontsize=22, y=1.02, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ec5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also individual cells overlay (to be done)\n",
    "\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION FOR OVERLAY\n",
    "# ==========================================\n",
    "# List mutants (by Treatment name) and controls (by Well_ID) to show individual cells\n",
    "CELL_OVERLAY_MUTANTS = [\"glmM\", \"glmS\"] \n",
    "CELL_OVERLAY_CONTROLS = [\"PLATE1_T2_E11\"] \n",
    "\n",
    "# Colors for the specific overlays\n",
    "overlay_colors = ['cyan', 'lime', 'magenta', 'orange', 'yellow']\n",
    "\n",
    "# ==========================================\n",
    "# UMAP & PLOTTING\n",
    "# ==========================================\n",
    "fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # 1. Prepare Well-Level Data\n",
    "    X_wells = wells[config['indices']].values\n",
    "    scaler = StandardScaler()\n",
    "    X_wells_scaled = scaler.fit_transform(X_wells)\n",
    "    \n",
    "    # 2. Fit UMAP on Wells\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_wells_scaled)\n",
    "    \n",
    "    # 3. Plot Background (All Wells)\n",
    "    is_control = wells[TREATMENT_COL] == CONTROL_NAME\n",
    "    ax.scatter(embedding[is_control, 0], embedding[is_control, 1], \n",
    "               c='red', marker='x', s=100, label='Control Wells', zorder=2, alpha=0.5)\n",
    "    ax.scatter(embedding[~is_control, 0], embedding[~is_control, 1], \n",
    "               c='black', marker='o', s=40, label='Mutant Wells', zorder=1, alpha=0.3)\n",
    "\n",
    "    # 4. OVERLAY INDIVIDUAL CELLS\n",
    "    color_idx = 0\n",
    "    \n",
    "    # Process Mutants in the list\n",
    "    for mutant in CELL_OVERLAY_MUTANTS:\n",
    "        # Find all wells matching this treatment\n",
    "        matching_wells = wells[wells[TREATMENT_COL] == mutant][\"Well_ID\"].values\n",
    "        all_cells = []\n",
    "        for w_id in matching_wells:\n",
    "            if w_id in well_storage:\n",
    "                all_cells.append(np.vstack(well_storage[w_id]))\n",
    "        \n",
    "        if all_cells:\n",
    "            # Get features for specific channels, scale them, and transform through UMAP\n",
    "            X_cells = np.vstack(all_cells)[:, config['indices']]\n",
    "            X_cells_scaled = scaler.transform(X_cells) # Use well-level scaler!\n",
    "            cell_embed = reducer.transform(X_cells_scaled) # Transform into well-space\n",
    "            \n",
    "            c = overlay_colors[color_idx % len(overlay_colors)]\n",
    "            ax.scatter(cell_embed[:, 0], cell_embed[:, 1], c=c, s=5, alpha=0.2, \n",
    "                       label=f\"Cells: {mutant}\", zorder=3)\n",
    "            color_idx += 1\n",
    "\n",
    "    # Process Controls in the list\n",
    "    for ctrl_well in CELL_OVERLAY_CONTROLS:\n",
    "        if ctrl_well in well_storage:\n",
    "            X_cells = np.vstack(well_storage[ctrl_well])[:, config['indices']]\n",
    "            X_cells_scaled = scaler.transform(X_cells)\n",
    "            cell_embed = reducer.transform(X_cells_scaled)\n",
    "            \n",
    "            c = overlay_colors[color_idx % len(overlay_colors)]\n",
    "            ax.scatter(cell_embed[:, 0], cell_embed[:, 1], c=c, s=5, alpha=0.2, \n",
    "                       label=f\"Cells: {ctrl_well}\", zorder=3, marker='.')\n",
    "            color_idx += 1\n",
    "\n",
    "    # 5. Add Labels for Wells (Existing logic)\n",
    "    texts = []\n",
    "    # Only label the wells we are highlighting to keep it clean, or keep your old logic:\n",
    "    for i, row in wells.iterrows():\n",
    "        if row[TREATMENT_COL] in CELL_OVERLAY_MUTANTS or row[\"Well_ID\"] in CELL_OVERLAY_CONTROLS:\n",
    "            texts.append(ax.text(embedding[i, 0], embedding[i, 1], \n",
    "                                 row[\"Well_ID\"] if row[TREATMENT_COL] == CONTROL_NAME else row[TREATMENT_COL],\n",
    "                                 fontsize=9, fontweight='bold'))\n",
    "\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='->', color='black', lw=1))\n",
    "    \n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', markerscale=2)\n",
    "\n",
    "plt.suptitle(\"UMAP Well Medians with Individual Cell Overlay\", fontsize=22, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking met label, size threhsold 700, neibhours 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a66d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median over alles\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements1/Thesis/project_masking_label\"\n",
    "FEATURES_BASE = os.path.join(PROJECT_ROOT, \"outputs\", \"results\", \"features\")\n",
    "METADATA_PATH = os.path.join(PROJECT_ROOT, \"inputs\", \"metadata\", \"index.csv\")\n",
    "\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# ==========================================\n",
    "# 2. SINGLE-STEP WELL AGGREGATION\n",
    "# ==========================================\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "# Dictionary to store all cells per well: { \"Well_ID\": [list_of_feature_arrays] }\n",
    "well_storage = {}\n",
    "# Dictionary to map Well_ID back to its Treatment name\n",
    "well_to_treatment = {}\n",
    "\n",
    "print(\"Loading cells and grouping by Well...\")\n",
    "for i in tqdm(meta.index):\n",
    "    well_id = f\"{meta.loc[i, 'Metadata_Plate']}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "    treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "    \n",
    "    filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Plate\"]), \n",
    "                            str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            with np.load(filename) as data:\n",
    "                cells = data[\"features\"]\n",
    "                # Clean NaNs\n",
    "                cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                \n",
    "                if len(cells_f) > 0:\n",
    "                    if well_id not in well_storage:\n",
    "                        well_storage[well_id] = []\n",
    "                        well_to_treatment[well_id] = treatment\n",
    "                    \n",
    "                    well_storage[well_id].append(cells_f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Now calculate the median for each well using all pooled cells\n",
    "well_level_data = []\n",
    "\n",
    "print(\"Calculating Single Median per Well...\")\n",
    "for well_id, feature_list in tqdm(well_storage.items()):\n",
    "    # Stack all cells from all sites into one large array for this well\n",
    "    all_cells_in_well = np.vstack(feature_list)\n",
    "    \n",
    "    # Calculate median across the 0-axis (rows/cells)\n",
    "    well_median = np.median(all_cells_in_well, axis=0)\n",
    "    \n",
    "    # Store result\n",
    "    row = {\"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "    for idx, val in enumerate(well_median):\n",
    "        row[idx] = val\n",
    "    well_level_data.append(row)\n",
    "\n",
    "wells = pd.DataFrame(well_level_data)\n",
    "\n",
    "print(f\"Aggregation complete. Processed {len(wells)} wells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced09ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. UMAP & PLOTTING (Full Standalone Cell)\n",
    "# ==========================================\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Ensure these match your aggregation cell variables\n",
    "CONTROL_NAME = \"no_sgRNA\" \n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# Define the channel subsets\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# Create Figure\n",
    "fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Processing UMAP for: {config['name']}...\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    X_subset = wells[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # 2. Run UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    # 3. Split Data for Plotting\n",
    "    is_control = wells[TREATMENT_COL] == CONTROL_NAME\n",
    "    \n",
    "    # Extract Control data\n",
    "    ctrl_embed = embedding[is_control]\n",
    "    ctrl_well_ids = wells[is_control][\"Well_ID\"].values\n",
    "    \n",
    "    # Extract Mutant data\n",
    "    mutant_embed = embedding[~is_control]\n",
    "    mutant_names = wells[~is_control][TREATMENT_COL].values\n",
    "    \n",
    "    # 4. Draw Scatter Points\n",
    "    # Controls as Red Crosses\n",
    "    ax.scatter(ctrl_embed[:, 0], ctrl_embed[:, 1], \n",
    "               c='red', marker='x', s=120, label='Control (no_sgRNA)', zorder=4)\n",
    "    \n",
    "    # Mutants as Black Dots\n",
    "    ax.scatter(mutant_embed[:, 0], mutant_embed[:, 1], \n",
    "               c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "    \n",
    "    # 5. Create Labels (Texts)\n",
    "    texts = []\n",
    "    \n",
    "    # Add Red Well_ID labels for Controls\n",
    "    for i, well_id in enumerate(ctrl_well_ids):\n",
    "        texts.append(ax.text(ctrl_embed[i, 0], ctrl_embed[i, 1], \n",
    "                             well_id, fontsize=7, color='red', fontweight='bold'))\n",
    "    \n",
    "    # Add Black Treatment labels for Mutants\n",
    "    for i, name in enumerate(mutant_names):\n",
    "        texts.append(ax.text(mutant_embed[i, 0], mutant_embed[i, 1], \n",
    "                             name, fontsize=8, color='black'))\n",
    "    \n",
    "    # 6. Adjust Labels to prevent overlaps\n",
    "    # arrowprops adds a subtle line from the text to the point if it moves\n",
    "    adjust_text(texts, ax=ax, \n",
    "                arrowprops=dict(arrowstyle='-', color='silver', lw=0.5),\n",
    "                only_move={'points':'y', 'text':'xy'}, \n",
    "                expand_points=(1.5, 1.5))\n",
    "    \n",
    "    # 7. Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', frameon=True, shadow=True)\n",
    "\n",
    "# Final global formatting\n",
    "plt.suptitle(f\"Channel Comparison UMAP - {len(wells)} Wells (Double Median Aggregation)\", \n",
    "             fontsize=22, y=1.02, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot (Optional)\n",
    "# plt.savefig(\"umap_channel_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T1_T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a068fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS (MULTI-PLATE)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/DataDeepprofiler\"\n",
    "PLATES = [\"PLATE1_T0\",\"PLATE1_T1\",\"PLATE1_T2\"] # List your folder names here\n",
    "\n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "all_plates_data = []\n",
    "\n",
    "for plate_id in PLATES:\n",
    "    print(f\"\\n--- Processing {plate_id} ---\")\n",
    "    \n",
    "    # Define paths specific to this plate\n",
    "    FEATURES_BASE = os.path.join(PROJECT_ROOT,\"features\", plate_id)\n",
    "    METADATA_PATH = os.path.join(PROJECT_ROOT,\"metadata\", f\"index_{plate_id}.csv\")\n",
    "    \n",
    "    meta = pd.read_csv(METADATA_PATH)\n",
    "    well_storage = {}\n",
    "    well_to_treatment = {}\n",
    "\n",
    "    # Load cells per well\n",
    "    for i in tqdm(meta.index, desc=f\"Loading {plate_id}\"):\n",
    "        well_id = f\"{plate_id}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "        treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "        \n",
    "        # Adjust filename path logic to match your folder structure\n",
    "        filename = os.path.join(FEATURES_BASE, \n",
    "                                str(meta.loc[i, \"Metadata_Well\"]), \n",
    "                                f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            try:\n",
    "                with np.load(filename) as data:\n",
    "                    cells = data[\"features\"]\n",
    "                    cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                    \n",
    "                    if len(cells_f) > 0:\n",
    "                        if well_id not in well_storage:\n",
    "                            well_storage[well_id] = []\n",
    "                            well_to_treatment[well_id] = treatment\n",
    "                        well_storage[well_id].append(cells_f)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Calculate median per well for THIS plate\n",
    "    for well_id, feature_list in well_storage.items():\n",
    "        all_cells_in_well = np.vstack(feature_list)\n",
    "        well_median = np.median(all_cells_in_well, axis=0)\n",
    "        \n",
    "        row = {\"Plate\": plate_id, \"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "        for idx, val in enumerate(well_median):\n",
    "            row[idx] = val\n",
    "        all_plates_data.append(row)\n",
    "\n",
    "# Combine everything into one giant DataFrame\n",
    "wells_df = pd.DataFrame(all_plates_data)\n",
    "print(f\"\\nAggregation complete. Total Wells: {len(wells_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Define the channel subsets (same as before)\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# LOOP THROUGH EACH PLATE INDIVIDUALLY\n",
    "for plate_id in wells_df['Plate'].unique():\n",
    "    plate_subset = wells_df[wells_df['Plate'] == plate_id].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config in enumerate(plot_configs):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # 1. Prepare & Scale Data\n",
    "        X_subset = plate_subset[config['indices']].values\n",
    "        X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "        \n",
    "        # 2. Run UMAP\n",
    "        reducer = umap.UMAP(n_neighbors=min(15, len(plate_subset)-1), min_dist=0.1, random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        \n",
    "        # 3. Plotting logic (same as your original code)\n",
    "        is_control = plate_subset[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Draw Control vs Mutants\n",
    "        ax.scatter(embedding[is_control, 0], embedding[is_control, 1], \n",
    "                   c='red', marker='x', s=120, label='Control', zorder=4)\n",
    "        ax.scatter(embedding[~is_control, 0], embedding[~is_control, 1], \n",
    "                   c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "\n",
    "        # 4. Text Labels (using subset data)\n",
    "        texts = []\n",
    "        for i, row in enumerate(plate_subset.itertuples()):\n",
    "            color = 'red' if row.Treatment == \"no_sgRNA\" else 'black'\n",
    "            label = row.Well_ID if row.Treatment == \"no_sgRNA\" else row.Treatment\n",
    "            texts.append(ax.text(embedding[i, 0], embedding[i, 1], label, fontsize=7, color=color))\n",
    "\n",
    "        adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='silver', lw=0.5))\n",
    "        ax.set_title(f\"{plate_id} - {config['name']}\")\n",
    "\n",
    "    plt.suptitle(f\"UMAP Analysis: {plate_id}\", fontsize=22, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"umap_{plate_id}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf11167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# 1. Setup Colors for Time Points (Plates)\n",
    "# You can use a specific color map or define a manual dictionary\n",
    "plate_list = sorted(wells_df['Plate'].unique())  # Ensures T0, T1, T2 order\n",
    "colors = ['#66c2a5', '#fc8d62', '#8da0cb'] # Qualitative colors (or use a gradient)\n",
    "plate_color_map = {plate: colors[i] for i, plate in enumerate(plate_list)}\n",
    "\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(28, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Running UMAP for {config['name']}...\")\n",
    "    \n",
    "    # 1. Scale all data together\n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # 2. Run UMAP (on the whole dataset)\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    # 3. Plot Plate by Plate\n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        \n",
    "        # Separate Control and Mutants within this plate\n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Plot Mutants (Dots)\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   c=plate_color_map[plate], marker='o', s=60, alpha=0.6, \n",
    "                   label=f\"{plate} (Mutant)\")\n",
    "        \n",
    "        # Plot Controls (Crosses - kept red to stand out, or use plate color)\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   edgecolors=plate_color_map[plate], facecolors='none', marker='s', s=130, \n",
    "                   linewidths=2, label=f\"{plate} (Control)\")\n",
    "\n",
    "        # 4. Add labels for this plate\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            # Only label Mutants to avoid clutter, or label everything\n",
    "            label = f\"{row.Treatment}_{row.Plate.split('_')[-1]}\" # e.g. \"MutantA_T0\"\n",
    "            texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                 fontsize=6, color=plate_color_map[plate]))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='best', markerscale=1, fontsize=10, ncol=2)\n",
    "    \n",
    "    # Prevent overlap\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.3))\n",
    "\n",
    "plt.suptitle(\"Combined UMAP: Time-Series Progression (T0 -> T1 -> T2)\", fontsize=24, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####with sphering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/DataDeepprofiler\"\n",
    "PLATES = [\"PLATE1_T0\", \"PLATE1_T1\", \"PLATE1_T2\"]\n",
    "\n",
    "TREATMENT_COL = \"Treatment\"\n",
    "CONTROL_NAME = \"no_sgRNA\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "\n",
    "# ==========================================\n",
    "# 2. HELPER FUNCTION: SPHERING (WHITENING)\n",
    "# ==========================================\n",
    "def apply_sphering(df, feat_cols, control_val=\"no_sgRNA\", reg_param=0.01):\n",
    "    \"\"\"\n",
    "    Applies ZCA-Whitening to a dataframe based on its control samples.\n",
    "    \"\"\"\n",
    "    X = df[feat_cols].values\n",
    "    control_mask = df[TREATMENT_COL] == control_val\n",
    "    X_control = X[control_mask]\n",
    "    \n",
    "    if len(X_control) < 2:\n",
    "        print(f\"Warning: Not enough control wells to sphere. Skipping whitening.\")\n",
    "        return df\n",
    "\n",
    "    # Center based on control mean\n",
    "    mu_control = np.mean(X_control, axis=0)\n",
    "    X_centered = X - mu_control\n",
    "    X_ctrl_centered = X_control - mu_control\n",
    "    \n",
    "    # Covariance & SVD\n",
    "    sigma = np.dot(X_ctrl_centered.T, X_ctrl_centered) / (X_ctrl_centered.shape[0] - 1)\n",
    "    # Adding regularization (REG_PARAM) to the diagonal for stability\n",
    "    sigma = sigma + reg_param * np.eye(sigma.shape[0])\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(sigma)\n",
    "    \n",
    "    # ZCA Whitening matrix\n",
    "    # W = U * diag(1/sqrt(lambda)) * U.T\n",
    "    W = np.dot(eigenvectors, np.dot(np.diag(1.0 / np.sqrt(eigenvalues + 1e-6)), eigenvectors.T))\n",
    "    \n",
    "    X_white = np.dot(X_centered, W)\n",
    "    \n",
    "    df_white = df.copy()\n",
    "    df_white[feat_cols] = X_white\n",
    "    return df_white\n",
    "\n",
    "# ==========================================\n",
    "# 3. AGGREGATION LOOP\n",
    "# ==========================================\n",
    "all_plates_list = []\n",
    "\n",
    "for plate_id in PLATES:\n",
    "    print(f\"\\n--- Aggregating {plate_id} ---\")\n",
    "    FEATURES_BASE = os.path.join(PROJECT_ROOT, \"features\", plate_id)\n",
    "    METADATA_PATH = os.path.join(PROJECT_ROOT, \"metadata\", f\"index_{plate_id}.csv\")\n",
    "    \n",
    "    meta = pd.read_csv(METADATA_PATH)\n",
    "    well_storage = {}\n",
    "    well_to_treatment = {}\n",
    "\n",
    "    for i in tqdm(meta.index, desc=f\"Loading cells\"):\n",
    "        well_id = f\"{plate_id}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "        treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "        filename = os.path.join(FEATURES_BASE, str(meta.loc[i, \"Metadata_Well\"]), f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            try:\n",
    "                with np.load(filename) as data:\n",
    "                    cells = data[\"features\"]\n",
    "                    cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                    if len(cells_f) > 0:\n",
    "                        if well_id not in well_storage:\n",
    "                            well_storage[well_id] = []\n",
    "                            well_to_treatment[well_id] = treatment\n",
    "                        well_storage[well_id].append(cells_f)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Calculate Medians for the current plate\n",
    "    current_plate_rows = []\n",
    "    for well_id, feature_list in well_storage.items():\n",
    "        all_cells_in_well = np.vstack(feature_list)\n",
    "        well_median = np.median(all_cells_in_well, axis=0)\n",
    "        row = {\"Plate\": plate_id, \"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "        for idx, val in enumerate(well_median):\n",
    "            row[idx] = val\n",
    "        current_plate_rows.append(row)\n",
    "    \n",
    "    # Convert plate to DF and immediately sphere it\n",
    "    plate_df = pd.DataFrame(current_plate_rows)\n",
    "    print(f\"Applying Sphering to {plate_id}...\")\n",
    "    plate_df_white = apply_sphering(plate_df, feature_cols, control_val=CONTROL_NAME)\n",
    "    \n",
    "    all_plates_list.append(plate_df_white)\n",
    "\n",
    "# Final combined and whitened dataframe\n",
    "wells_df = pd.concat(all_plates_list, ignore_index=True)\n",
    "print(f\"\\nAggregation & Sphering complete. Total Wells: {len(wells_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc96a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Plate Color Mapping\n",
    "plate_list = sorted(wells_df['Plate'].unique())\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c'] # Blue, Orange, Green for T0, T1, T2\n",
    "plate_color_map = {plate: colors[i] for i, plate in enumerate(plate_list)}\n",
    "\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"UMAP for {config['name']}...\")\n",
    "    \n",
    "    # Scale across all plates (standardizing the whitened ranges)\n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        \n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == CONTROL_NAME\n",
    "        p_color = plate_color_map[plate]\n",
    "        \n",
    "        # Plot Mutants\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   c=p_color, marker='o', s=70, alpha=0.6, label=f\"{plate}\")\n",
    "        \n",
    "        # Plot Controls (Red X's for all plates to see if they overlap in center)\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   c='red', marker='x', s=100, alpha=0.8)\n",
    "\n",
    "        # Labels\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            if row.Treatment != CONTROL_NAME:\n",
    "                label = f\"{row.Treatment}_{row.Plate[-2:]}\" # e.g. MutantA_T0\n",
    "                texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                     fontsize=7, color=p_color))\n",
    "\n",
    "    ax.set_title(f\"{config['name']}\", fontweight='bold')\n",
    "    if idx == 0:\n",
    "        ax.legend(title=\"Plates\", loc='best')\n",
    "\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='silver', lw=0.5))\n",
    "\n",
    "plt.suptitle(\"Whitened Multi-Plate UMAP (By Channel Subset)\", fontsize=22, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fcf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLATE1 en 2 T1 en T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS (MULTI-PLATE)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/DataDeepprofiler\"\n",
    "PLATES = [\"PLATE1_T0\",\"PLATE1_T1\",\"PLATE1_T2\",\"PLATE2_T0\",\"PLATE2_T1\",\"PLATE2_T2\"] # List your folder names here\n",
    "\n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "all_plates_data = []\n",
    "\n",
    "for plate_id in PLATES:\n",
    "    print(f\"\\n--- Processing {plate_id} ---\")\n",
    "    \n",
    "    # Define paths specific to this plate\n",
    "    FEATURES_BASE = os.path.join(PROJECT_ROOT,\"features\", plate_id)\n",
    "    METADATA_PATH = os.path.join(PROJECT_ROOT,\"metadata\", f\"index_{plate_id}.csv\")\n",
    "    \n",
    "    meta = pd.read_csv(METADATA_PATH)\n",
    "    well_storage = {}\n",
    "    well_to_treatment = {}\n",
    "\n",
    "    # Load cells per well\n",
    "    for i in tqdm(meta.index, desc=f\"Loading {plate_id}\"):\n",
    "        well_id = f\"{plate_id}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "        treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "        \n",
    "        # Adjust filename path logic to match your folder structure\n",
    "        filename = os.path.join(FEATURES_BASE, \n",
    "                                str(meta.loc[i, \"Metadata_Well\"]), \n",
    "                                f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            try:\n",
    "                with np.load(filename) as data:\n",
    "                    cells = data[\"features\"]\n",
    "                    cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                    \n",
    "                    if len(cells_f) > 0:\n",
    "                        if well_id not in well_storage:\n",
    "                            well_storage[well_id] = []\n",
    "                            well_to_treatment[well_id] = treatment\n",
    "                        well_storage[well_id].append(cells_f)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Calculate median per well for THIS plate\n",
    "    for well_id, feature_list in well_storage.items():\n",
    "        all_cells_in_well = np.vstack(feature_list)\n",
    "        well_median = np.median(all_cells_in_well, axis=0)\n",
    "        \n",
    "        row = {\"Plate\": plate_id, \"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "        for idx, val in enumerate(well_median):\n",
    "            row[idx] = val\n",
    "        all_plates_data.append(row)\n",
    "\n",
    "# Combine everything into one giant DataFrame\n",
    "wells_df = pd.DataFrame(all_plates_data)\n",
    "print(f\"\\nAggregation complete. Total Wells: {len(wells_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d203709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Define the channel subsets (same as before)\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# LOOP THROUGH EACH PLATE INDIVIDUALLY\n",
    "for plate_id in wells_df['Plate'].unique():\n",
    "    plate_subset = wells_df[wells_df['Plate'] == plate_id].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config in enumerate(plot_configs):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # 1. Prepare & Scale Data\n",
    "        X_subset = plate_subset[config['indices']].values\n",
    "        X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "        \n",
    "        # 2. Run UMAP\n",
    "        reducer = umap.UMAP(n_neighbors=min(15, len(plate_subset)-1), min_dist=0.1, random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        \n",
    "        # 3. Plotting logic (same as your original code)\n",
    "        is_control = plate_subset[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Draw Control vs Mutants\n",
    "        ax.scatter(embedding[is_control, 0], embedding[is_control, 1], \n",
    "                   c='red', marker='x', s=120, label='Control', zorder=4)\n",
    "        ax.scatter(embedding[~is_control, 0], embedding[~is_control, 1], \n",
    "                   c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "\n",
    "        # 4. Text Labels (using subset data)\n",
    "        texts = []\n",
    "        for i, row in enumerate(plate_subset.itertuples()):\n",
    "            color = 'red' if row.Treatment == \"no_sgRNA\" else 'black'\n",
    "            label = row.Well_ID if row.Treatment == \"no_sgRNA\" else row.Treatment\n",
    "            texts.append(ax.text(embedding[i, 0], embedding[i, 1], label, fontsize=7, color=color))\n",
    "\n",
    "        adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='silver', lw=0.5))\n",
    "        ax.set_title(f\"{plate_id} - {config['name']}\")\n",
    "\n",
    "    plt.suptitle(f\"UMAP Analysis: {plate_id}\", fontsize=22, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"umap_{plate_id}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Dynamic Color Setup ---\n",
    "plate_list = sorted(wells_df['Plate'].unique())\n",
    "num_plates = len(plate_list)\n",
    "\n",
    "# Use a qualitative colormap (Set1, Set3, or Dark2 are good for distinct categories)\n",
    "# 'tab10' or 'tab20' are excellent for up to 10 or 20 distinct categories\n",
    "cmap = plt.get_cmap('tab10') \n",
    "plate_colors = [cmap(i) for i in np.linspace(0, 1, num_plates)]\n",
    "plate_color_map = {plate: plate_colors[i] for i, plate in enumerate(plate_list)}\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(28, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Running UMAP for {config['name']}...\")\n",
    "    \n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    # 3. Plot Plate by Plate\n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        \n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Plot Mutants (Filled Circles)\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   color=plate_color_map[plate], marker='o', s=60, alpha=0.6, \n",
    "                   label=f\"{plate} (Mutant)\")\n",
    "        \n",
    "        # Plot Controls (Open Squares)\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   edgecolors=plate_color_map[plate], facecolors='none', \n",
    "                   marker='s', s=130, linewidths=2, label=f\"{plate} (Control)\")\n",
    "\n",
    "        # 4. Add labels\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            label = f\"{row.Treatment}_{row.Plate.split('_')[-1]}\"\n",
    "            texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                 fontsize=6, color=plate_color_map[plate]))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Move legend to the side if it gets too crowded with 6+ plates\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), markerscale=1, fontsize=8, ncol=1)\n",
    "    \n",
    "    # Adjust text to prevent overlapping labels\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.3))\n",
    "\n",
    "plt.suptitle(\"Combined UMAP: Multi-Plate Analysis\", fontsize=24, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne and pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# --- 1. Configuration & Setup ---\n",
    "# Choose your method here: \"PCA\" or \"TSNE\"\n",
    "REDUCTION_METHOD = \"PCA\" \n",
    "\n",
    "plate_list = sorted(wells_df['Plate'].unique())\n",
    "num_plates = len(plate_list)\n",
    "cmap = plt.get_cmap('tab10')\n",
    "plate_color_map = {plate: cmap(i % 10) for i, plate in enumerate(plate_list)}\n",
    "\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(28, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- 2. Iterative Plotting ---\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Running {REDUCTION_METHOD} for {config['name']}...\")\n",
    "    \n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # Switch logic for Dimensionality Reduction\n",
    "    if REDUCTION_METHOD == \"PCA\":\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        expl_var = reducer.explained_variance_ratio_\n",
    "        xlabel, ylabel = f\"PC1 ({expl_var[0]:.1%})\", f\"PC2 ({expl_var[1]:.1%})\"\n",
    "    else:\n",
    "        # t-SNE: Perplexity is key! (usually 5-50)\n",
    "        reducer = TSNE(n_components=2, perplexity=min(30, len(wells_df)-1), \n",
    "                       init='pca', learning_rate='auto', random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        xlabel, ylabel = \"t-SNE 1\", \"t-SNE 2\"\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Mutants\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   color=plate_color_map[plate], marker='o', s=70, alpha=0.7, \n",
    "                   label=f\"{plate} (Mutant)\")\n",
    "        \n",
    "        # Controls\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   edgecolors=plate_color_map[plate], facecolors='none', \n",
    "                   marker='s', s=150, linewidths=2.5, label=f\"{plate} (Control)\")\n",
    "\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            label = f\"{row.Treatment}_{row.Plate.split('_')[-1]}\"\n",
    "            texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                 fontsize=7, color='black', alpha=0.8))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f\"{config['name']} ({REDUCTION_METHOD})\", fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=9)\n",
    "    \n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.2))\n",
    "\n",
    "plt.suptitle(f\"Combined {REDUCTION_METHOD}: Multi-Plate Analysis\", fontsize=26, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# --- 1. Configuration & Setup ---\n",
    "# Choose your method here: \"PCA\" or \"TSNE\"\n",
    "REDUCTION_METHOD = \"TSNE\" \n",
    "\n",
    "plate_list = sorted(wells_df['Plate'].unique())\n",
    "num_plates = len(plate_list)\n",
    "cmap = plt.get_cmap('tab10')\n",
    "plate_color_map = {plate: cmap(i % 10) for i, plate in enumerate(plate_list)}\n",
    "\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(28, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- 2. Iterative Plotting ---\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Running {REDUCTION_METHOD} for {config['name']}...\")\n",
    "    \n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    # Switch logic for Dimensionality Reduction\n",
    "    if REDUCTION_METHOD == \"PCA\":\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        expl_var = reducer.explained_variance_ratio_\n",
    "        xlabel, ylabel = f\"PC1 ({expl_var[0]:.1%})\", f\"PC2 ({expl_var[1]:.1%})\"\n",
    "    else:\n",
    "        # t-SNE: Perplexity is key! (usually 5-50)\n",
    "        reducer = TSNE(n_components=2, perplexity=min(30, len(wells_df)-1), \n",
    "                       init='pca', learning_rate='auto', random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        xlabel, ylabel = \"t-SNE 1\", \"t-SNE 2\"\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Mutants\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   color=plate_color_map[plate], marker='o', s=70, alpha=0.7, \n",
    "                   label=f\"{plate} (Mutant)\")\n",
    "        \n",
    "        # Controls\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   edgecolors=plate_color_map[plate], facecolors='none', \n",
    "                   marker='s', s=150, linewidths=2.5, label=f\"{plate} (Control)\")\n",
    "\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            label = f\"{row.Treatment}_{row.Plate.split('_')[-1]}\"\n",
    "            texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                 fontsize=7, color='black', alpha=0.8))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f\"{config['name']} ({REDUCTION_METHOD})\", fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=9)\n",
    "    \n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.2))\n",
    "\n",
    "plt.suptitle(f\"Combined {REDUCTION_METHOD}: Multi-Plate Analysis\", fontsize=26, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97573fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS (MULTI-PLATE)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/DataDeepprofiler\"\n",
    "PLATES = [\"PLATE1_T2\",\"PLATE2_T2_deduplication\"] # List your folder names here\n",
    "\n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "all_plates_data = []\n",
    "\n",
    "for plate_id in PLATES:\n",
    "    print(f\"\\n--- Processing {plate_id} ---\")\n",
    "    \n",
    "    # Define paths specific to this plate\n",
    "    FEATURES_BASE = os.path.join(PROJECT_ROOT,\"features\", plate_id)\n",
    "    METADATA_PATH = os.path.join(PROJECT_ROOT,\"metadata\", f\"index_{plate_id}.csv\")\n",
    "    \n",
    "    meta = pd.read_csv(METADATA_PATH)\n",
    "    well_storage = {}\n",
    "    well_to_treatment = {}\n",
    "\n",
    "    # Load cells per well\n",
    "    for i in tqdm(meta.index, desc=f\"Loading {plate_id}\"):\n",
    "        well_id = f\"{plate_id}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "        treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "        \n",
    "        # Adjust filename path logic to match your folder structure\n",
    "        filename = os.path.join(FEATURES_BASE, \n",
    "                                str(meta.loc[i, \"Metadata_Well\"]), \n",
    "                                f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            try:\n",
    "                with np.load(filename) as data:\n",
    "                    cells = data[\"features\"]\n",
    "                    cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                    \n",
    "                    if len(cells_f) > 0:\n",
    "                        if well_id not in well_storage:\n",
    "                            well_storage[well_id] = []\n",
    "                            well_to_treatment[well_id] = treatment\n",
    "                        well_storage[well_id].append(cells_f)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Calculate median per well for THIS plate\n",
    "    for well_id, feature_list in well_storage.items():\n",
    "        all_cells_in_well = np.vstack(feature_list)\n",
    "        well_median = np.median(all_cells_in_well, axis=0)\n",
    "        \n",
    "        row = {\"Plate\": plate_id, \"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "        for idx, val in enumerate(well_median):\n",
    "            row[idx] = val\n",
    "        all_plates_data.append(row)\n",
    "\n",
    "# Combine everything into one giant DataFrame\n",
    "wells_df = pd.DataFrame(all_plates_data)\n",
    "print(f\"\\nAggregation complete. Total Wells: {len(wells_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21595bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Dynamic Color Setup ---\n",
    "plate_list = sorted(wells_df['Plate'].unique())\n",
    "num_plates = len(plate_list)\n",
    "\n",
    "# Use a qualitative colormap (Set1, Set3, or Dark2 are good for distinct categories)\n",
    "# 'tab10' or 'tab20' are excellent for up to 10 or 20 distinct categories\n",
    "cmap = plt.get_cmap('tab10') \n",
    "plate_colors = [cmap(i) for i in np.linspace(0, 1, num_plates)]\n",
    "plate_color_map = {plate: plate_colors[i] for i, plate in enumerate(plate_list)}\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(28, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Running UMAP for {config['name']}...\")\n",
    "    \n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    # 3. Plot Plate by Plate\n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        \n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Plot Mutants (Filled Circles)\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   color=plate_color_map[plate], marker='o', s=60, alpha=0.6, \n",
    "                   label=f\"{plate} (Mutant)\")\n",
    "        \n",
    "        # Plot Controls (Open Squares)\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   edgecolors=plate_color_map[plate], facecolors='none', \n",
    "                   marker='s', s=130, linewidths=2, label=f\"{plate} (Control)\")\n",
    "\n",
    "        # 4. Add labels\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            label = f\"{row.Treatment}_{row.Plate.split('_')[-1]}\"\n",
    "            texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                 fontsize=6, color=plate_color_map[plate]))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Move legend to the side if it gets too crowded with 6+ plates\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), markerscale=1, fontsize=8, ncol=1)\n",
    "    \n",
    "    # Adjust text to prevent overlapping labels\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.3))\n",
    "\n",
    "plt.suptitle(\"Combined UMAP: Multi-Plate Analysis\", fontsize=24, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS (MULTI-PLATE)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/DataDeepprofiler\"\n",
    "PLATES = [\"PLATE2_T0_deduplication\",\"PLATE2_T1_deduplication\",\"PLATE2_T2_deduplication\"] # List your folder names here\n",
    "\n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "all_plates_data = []\n",
    "\n",
    "for plate_id in PLATES:\n",
    "    print(f\"\\n--- Processing {plate_id} ---\")\n",
    "    \n",
    "    # Define paths specific to this plate\n",
    "    FEATURES_BASE = os.path.join(PROJECT_ROOT,\"features\", plate_id)\n",
    "    METADATA_PATH = os.path.join(PROJECT_ROOT,\"metadata\", f\"index_{plate_id}.csv\")\n",
    "    \n",
    "    meta = pd.read_csv(METADATA_PATH)\n",
    "    well_storage = {}\n",
    "    well_to_treatment = {}\n",
    "\n",
    "    # Load cells per well\n",
    "    for i in tqdm(meta.index, desc=f\"Loading {plate_id}\"):\n",
    "        well_id = f\"{plate_id}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "        treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "        \n",
    "        # Adjust filename path logic to match your folder structure\n",
    "        filename = os.path.join(FEATURES_BASE, \n",
    "                                str(meta.loc[i, \"Metadata_Well\"]), \n",
    "                                f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            try:\n",
    "                with np.load(filename) as data:\n",
    "                    cells = data[\"features\"]\n",
    "                    cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                    \n",
    "                    if len(cells_f) > 0:\n",
    "                        if well_id not in well_storage:\n",
    "                            well_storage[well_id] = []\n",
    "                            well_to_treatment[well_id] = treatment\n",
    "                        well_storage[well_id].append(cells_f)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Calculate median per well for THIS plate\n",
    "    for well_id, feature_list in well_storage.items():\n",
    "        all_cells_in_well = np.vstack(feature_list)\n",
    "        well_median = np.median(all_cells_in_well, axis=0)\n",
    "        \n",
    "        row = {\"Plate\": plate_id, \"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "        for idx, val in enumerate(well_median):\n",
    "            row[idx] = val\n",
    "        all_plates_data.append(row)\n",
    "\n",
    "# Combine everything into one giant DataFrame\n",
    "wells_df = pd.DataFrame(all_plates_data)\n",
    "print(f\"\\nAggregation complete. Total Wells: {len(wells_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58768455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Define the channel subsets (same as before)\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# LOOP THROUGH EACH PLATE INDIVIDUALLY\n",
    "for plate_id in wells_df['Plate'].unique():\n",
    "    plate_subset = wells_df[wells_df['Plate'] == plate_id].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config in enumerate(plot_configs):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # 1. Prepare & Scale Data\n",
    "        X_subset = plate_subset[config['indices']].values\n",
    "        X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "        \n",
    "        # 2. Run UMAP\n",
    "        reducer = umap.UMAP(n_neighbors=min(15, len(plate_subset)-1), min_dist=0.1, random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        \n",
    "        # 3. Plotting logic (same as your original code)\n",
    "        is_control = plate_subset[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Draw Control vs Mutants\n",
    "        ax.scatter(embedding[is_control, 0], embedding[is_control, 1], \n",
    "                   c='red', marker='x', s=120, label='Control', zorder=4)\n",
    "        ax.scatter(embedding[~is_control, 0], embedding[~is_control, 1], \n",
    "                   c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "\n",
    "        # 4. Text Labels (using subset data)\n",
    "        texts = []\n",
    "        for i, row in enumerate(plate_subset.itertuples()):\n",
    "            color = 'red' if row.Treatment == \"no_sgRNA\" else 'black'\n",
    "            label = row.Well_ID if row.Treatment == \"no_sgRNA\" else row.Treatment\n",
    "            texts.append(ax.text(embedding[i, 0], embedding[i, 1], label, fontsize=7, color=color))\n",
    "\n",
    "        adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='silver', lw=0.5))\n",
    "        ax.set_title(f\"{plate_id} - {config['name']}\")\n",
    "\n",
    "    plt.suptitle(f\"UMAP Analysis: {plate_id}\", fontsize=22, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"umap_{plate_id}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90696ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS (MULTI-PLATE)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/DataDeepprofiler\"\n",
    "PLATES = [\"PLATE2_T0_deduplication\", \"PLATE2_T1_deduplication\", \"PLATE2_T2_deduplication\"]\n",
    "\n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "TOTAL_FEATURES = NUM_CHANNELS * FEATS_PER_CH\n",
    "\n",
    "all_plates_rows = []\n",
    "\n",
    "for plate_id in PLATES:\n",
    "    print(f\"\\n--- Processing {plate_id} ---\")\n",
    "    \n",
    "    # Define paths specific to this plate\n",
    "    FEATURES_BASE = os.path.join(PROJECT_ROOT, \"features\", plate_id)\n",
    "    METADATA_PATH = os.path.join(PROJECT_ROOT, \"metadata\", f\"index_{plate_id}.csv\")\n",
    "    \n",
    "    if not os.path.exists(METADATA_PATH):\n",
    "        print(f\"Warning: Metadata not found for {plate_id}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    meta = pd.read_csv(METADATA_PATH)\n",
    "    well_storage = {}\n",
    "    well_to_treatment = {}\n",
    "\n",
    "    # Load cells per well\n",
    "    for i in tqdm(meta.index, desc=f\"Loading {plate_id}\"):\n",
    "        well_name = str(meta.loc[i, 'Metadata_Well'])\n",
    "        well_id = f\"{plate_id}_{well_name}\"\n",
    "        treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "        \n",
    "        # Adjust filename path logic\n",
    "        filename = os.path.join(FEATURES_BASE, \n",
    "                                well_name, \n",
    "                                f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            try:\n",
    "                with np.load(filename) as data:\n",
    "                    cells = data[\"features\"]\n",
    "                    # Filter out NaNs\n",
    "                    cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                    \n",
    "                    if len(cells_f) > 0:\n",
    "                        if well_id not in well_storage:\n",
    "                            well_storage[well_id] = []\n",
    "                            well_to_treatment[well_id] = treatment\n",
    "                        well_storage[well_id].append(cells_f)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    # Calculate MEAN per well for THIS plate\n",
    "    print(f\"Aggregating {len(well_storage)} wells...\")\n",
    "    for well_id, feature_list in well_storage.items():\n",
    "        # Stack all sites for this well into one array\n",
    "        all_cells_in_well = np.vstack(feature_list)\n",
    "        \n",
    "        # SWITCHED TO MEAN: Faster and captures the average signal\n",
    "        well_mean = np.mean(all_cells_in_well, axis=0)\n",
    "        \n",
    "        # Create a single row: Metadata + 6400 feature values\n",
    "        row_data = [plate_id, well_id, well_to_treatment[well_id]] + well_mean.tolist()\n",
    "        all_plates_rows.append(row_data)\n",
    "\n",
    "# ==========================================\n",
    "# 2. CREATE FINAL DATAFRAME\n",
    "# ==========================================\n",
    "# Generate column names: Metadata first, then feature indices\n",
    "feature_cols = [f\"feat_{i}\" for i in range(TOTAL_FEATURES)]\n",
    "columns = [\"Plate\", \"Well_ID\", \"Treatment\"] + feature_cols\n",
    "\n",
    "wells_df = pd.DataFrame(all_plates_rows, columns=columns)\n",
    "\n",
    "print(f\"\\n--- SUCCESS ---\")\n",
    "print(f\"Aggregation complete. Total Wells: {len(wells_df)}\")\n",
    "print(f\"Dataframe Shape: {wells_df.shape}\")\n",
    "\n",
    "# Optional: Display the first few rows\n",
    "# print(wells_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# 1. Define the channel subsets using the \"feat_N\" naming convention\n",
    "# This matches the column names created in the previous step\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": [f\"feat_{i}\" for i in range(TOTAL_FEATURES)]},\n",
    "    {\"name\": \"Channel 1\", \"indices\": [f\"feat_{i}\" for i in range(0, 1280)]},\n",
    "    {\"name\": \"Channel 2\", \"indices\": [f\"feat_{i}\" for i in range(1280, 2560)]},\n",
    "    {\"name\": \"Channel 3\", \"indices\": [f\"feat_{i}\" for i in range(2560, 3840)]},\n",
    "    {\"name\": \"Channel 4\", \"indices\": [f\"feat_{i}\" for i in range(3840, 5120)]},\n",
    "    {\"name\": \"Channel 5\", \"indices\": [f\"feat_{i}\" for i in range(5120, 6400)]}\n",
    "]\n",
    "\n",
    "# 2. LOOP THROUGH EACH PLATE INDIVIDUALLY\n",
    "for plate_id in wells_df['Plate'].unique():\n",
    "    plate_subset = wells_df[wells_df['Plate'] == plate_id].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Check if we have enough data to plot\n",
    "    if len(plate_subset) < 2:\n",
    "        print(f\"Skipping {plate_id}: Not enough wells for UMAP.\")\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config in enumerate(plot_configs):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # 1. Prepare & Scale Data\n",
    "        # Accessing by the string names we created (feat_0, feat_1...)\n",
    "        X_subset = plate_subset[config['indices']].values\n",
    "        X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "        \n",
    "        # 2. Run UMAP\n",
    "        # n_neighbors cannot be larger than the number of samples\n",
    "        n_neigh = min(15, len(plate_subset) - 1)\n",
    "        reducer = umap.UMAP(n_neighbors=n_neigh, min_dist=0.1, random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        \n",
    "        # 3. Plotting logic\n",
    "        # Filter for control group labels\n",
    "        is_control = plate_subset['Treatment'] == \"no_sgRNA\"\n",
    "        \n",
    "        # Draw Control vs Mutants\n",
    "        ax.scatter(embedding[is_control, 0], embedding[is_control, 1], \n",
    "                   c='red', marker='x', s=120, label='Control', zorder=4)\n",
    "        ax.scatter(embedding[~is_control, 0], embedding[~is_control, 1], \n",
    "                   c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "\n",
    "        # 4. Text Labels\n",
    "        texts = []\n",
    "        for i, row in enumerate(plate_subset.itertuples()):\n",
    "            color = 'red' if row.Treatment == \"no_sgRNA\" else 'black'\n",
    "            # Label with Well_ID if control, otherwise use Treatment name\n",
    "            label = row.Well_ID if row.Treatment == \"no_sgRNA\" else row.Treatment\n",
    "            texts.append(ax.text(embedding[i, 0], embedding[i, 1], label, fontsize=8, color=color))\n",
    "\n",
    "        # Avoid overlapping labels\n",
    "        adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='silver', lw=0.5))\n",
    "        ax.set_title(f\"{config['name']}\", fontsize=14)\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f\"UMAP Analysis (Mean Aggregation): {plate_id}\", fontsize=22, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"umap_mean_{plate_id}.png\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23195b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ea3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PATHS (MULTI-PLATE)\n",
    "# ==========================================\n",
    "PROJECT_ROOT = \"/media/arnout/Elements/groteEdeepprofilerdingen/DataDeepprofiler\"\n",
    "PLATES = [\"PLATE2_T0\",\"PLATE2_T1\",\"PLATE2_T2\", \"PLATE2_T0_masking\",\"PLATE2_T1_masking\",\"PLATE2_T2_masking\"] # List your folder names here\n",
    "\n",
    "TREATMENT_COL = \"Treatment\"\n",
    "NUM_CHANNELS = 5\n",
    "FEATS_PER_CH = 1280\n",
    "\n",
    "all_plates_data = []\n",
    "\n",
    "for plate_id in PLATES:\n",
    "    print(f\"\\n--- Processing {plate_id} ---\")\n",
    "    \n",
    "    # Define paths specific to this plate\n",
    "    FEATURES_BASE = os.path.join(PROJECT_ROOT,\"features\", plate_id)\n",
    "    METADATA_PATH = os.path.join(PROJECT_ROOT,\"metadata\", f\"index_{plate_id}.csv\")\n",
    "    \n",
    "    meta = pd.read_csv(METADATA_PATH)\n",
    "    well_storage = {}\n",
    "    well_to_treatment = {}\n",
    "\n",
    "    # Load cells per well\n",
    "    for i in tqdm(meta.index, desc=f\"Loading {plate_id}\"):\n",
    "        well_id = f\"{plate_id}_{meta.loc[i, 'Metadata_Well']}\"\n",
    "        treatment = str(meta.loc[i, TREATMENT_COL]).strip()\n",
    "        \n",
    "        # Adjust filename path logic to match your folder structure\n",
    "        filename = os.path.join(FEATURES_BASE, \n",
    "                                str(meta.loc[i, \"Metadata_Well\"]), \n",
    "                                f\"{meta.loc[i, 'Metadata_Site']}.npz\")\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            try:\n",
    "                with np.load(filename) as data:\n",
    "                    cells = data[\"features\"]\n",
    "                    cells_f = cells[~np.isnan(cells).any(axis=1)]\n",
    "                    \n",
    "                    if len(cells_f) > 0:\n",
    "                        if well_id not in well_storage:\n",
    "                            well_storage[well_id] = []\n",
    "                            well_to_treatment[well_id] = treatment\n",
    "                        well_storage[well_id].append(cells_f)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Calculate median per well for THIS plate\n",
    "    for well_id, feature_list in well_storage.items():\n",
    "        all_cells_in_well = np.vstack(feature_list)\n",
    "        well_median = np.median(all_cells_in_well, axis=0)\n",
    "        \n",
    "        row = {\"Plate\": plate_id, \"Well_ID\": well_id, \"Treatment\": well_to_treatment[well_id]}\n",
    "        for idx, val in enumerate(well_median):\n",
    "            row[idx] = val\n",
    "        all_plates_data.append(row)\n",
    "\n",
    "# Combine everything into one giant DataFrame\n",
    "wells_df = pd.DataFrame(all_plates_data)\n",
    "print(f\"\\nAggregation complete. Total Wells: {len(wells_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Define the channel subsets (same as before)\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "# LOOP THROUGH EACH PLATE INDIVIDUALLY\n",
    "for plate_id in wells_df['Plate'].unique():\n",
    "    plate_subset = wells_df[wells_df['Plate'] == plate_id].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(26, 18))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config in enumerate(plot_configs):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # 1. Prepare & Scale Data\n",
    "        X_subset = plate_subset[config['indices']].values\n",
    "        X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "        \n",
    "        # 2. Run UMAP\n",
    "        reducer = umap.UMAP(n_neighbors=min(15, len(plate_subset)-1), min_dist=0.1, random_state=42)\n",
    "        embedding = reducer.fit_transform(X_scaled)\n",
    "        \n",
    "        # 3. Plotting logic (same as your original code)\n",
    "        is_control = plate_subset[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Draw Control vs Mutants\n",
    "        ax.scatter(embedding[is_control, 0], embedding[is_control, 1], \n",
    "                   c='red', marker='x', s=120, label='Control', zorder=4)\n",
    "        ax.scatter(embedding[~is_control, 0], embedding[~is_control, 1], \n",
    "                   c='black', marker='o', s=50, alpha=0.5, label='Mutants', zorder=3)\n",
    "\n",
    "        # 4. Text Labels (using subset data)\n",
    "        texts = []\n",
    "        for i, row in enumerate(plate_subset.itertuples()):\n",
    "            color = 'red' if row.Treatment == \"no_sgRNA\" else 'black'\n",
    "            label = row.Well_ID if row.Treatment == \"no_sgRNA\" else row.Treatment\n",
    "            texts.append(ax.text(embedding[i, 0], embedding[i, 1], label, fontsize=7, color=color))\n",
    "\n",
    "        adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='silver', lw=0.5))\n",
    "        ax.set_title(f\"{plate_id} - {config['name']}\")\n",
    "\n",
    "    plt.suptitle(f\"UMAP Analysis: {plate_id}\", fontsize=22, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"umap_{plate_id}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c824ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Dynamic Color Setup ---\n",
    "plate_list = sorted(wells_df['Plate'].unique())\n",
    "num_plates = len(plate_list)\n",
    "\n",
    "# Use a qualitative colormap (Set1, Set3, or Dark2 are good for distinct categories)\n",
    "# 'tab10' or 'tab20' are excellent for up to 10 or 20 distinct categories\n",
    "cmap = plt.get_cmap('tab10') \n",
    "plate_colors = [cmap(i) for i in np.linspace(0, 1, num_plates)]\n",
    "plate_color_map = {plate: plate_colors[i] for i, plate in enumerate(plate_list)}\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(28, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Running UMAP for {config['name']}...\")\n",
    "    \n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    # 3. Plot Plate by Plate\n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        \n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Plot Mutants (Filled Circles)\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   color=plate_color_map[plate], marker='o', s=60, alpha=0.6, \n",
    "                   label=f\"{plate} (Mutant)\")\n",
    "        \n",
    "        # Plot Controls (Open Squares)\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   edgecolors=plate_color_map[plate], facecolors='none', \n",
    "                   marker='s', s=130, linewidths=2, label=f\"{plate} (Control)\")\n",
    "\n",
    "        # 4. Add labels\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            label = f\"{row.Treatment}_{row.Plate.split('_')[-1]}\"\n",
    "            texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                 fontsize=6, color=plate_color_map[plate]))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Move legend to the side if it gets too crowded with 6+ plates\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), markerscale=1, fontsize=8, ncol=1)\n",
    "    \n",
    "    # Adjust text to prevent overlapping labels\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.3))\n",
    "\n",
    "plt.suptitle(\"Combined UMAP: Multi-Plate Analysis\", fontsize=24, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7decba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "PLATES = [\"PLATE2_T0_masking\",\"PLATE2_T1_masking\",\"PLATE2_T2_masking\"] \n",
    "\n",
    "# --- 1. Dynamic Color Setup ---\n",
    "plate_list = sorted(wells_df['Plate'].unique())\n",
    "num_plates = len(plate_list)\n",
    "\n",
    "# Use a qualitative colormap (Set1, Set3, or Dark2 are good for distinct categories)\n",
    "# 'tab10' or 'tab20' are excellent for up to 10 or 20 distinct categories\n",
    "cmap = plt.get_cmap('tab10') \n",
    "plate_colors = [cmap(i) for i in np.linspace(0, 1, num_plates)]\n",
    "plate_color_map = {plate: plate_colors[i] for i, plate in enumerate(plate_list)}\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "feature_cols = [i for i in range(NUM_CHANNELS * FEATS_PER_CH)]\n",
    "plot_configs = [\n",
    "    {\"name\": \"All Channels\", \"indices\": feature_cols},\n",
    "    {\"name\": \"Channel 1\", \"indices\": list(range(0, 1280))},\n",
    "    {\"name\": \"Channel 2\", \"indices\": list(range(1280, 2560))},\n",
    "    {\"name\": \"Channel 3\", \"indices\": list(range(2560, 3840))},\n",
    "    {\"name\": \"Channel 4\", \"indices\": list(range(3840, 5120))},\n",
    "    {\"name\": \"Channel 5\", \"indices\": list(range(5120, 6400))}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(28, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, config in enumerate(plot_configs):\n",
    "    ax = axes[idx]\n",
    "    print(f\"Running UMAP for {config['name']}...\")\n",
    "    \n",
    "    X_subset = wells_df[config['indices']].values\n",
    "    X_scaled = StandardScaler().fit_transform(X_subset)\n",
    "    \n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    # 3. Plot Plate by Plate\n",
    "    for plate in plate_list:\n",
    "        mask = wells_df['Plate'] == plate\n",
    "        plate_embed = embedding[mask]\n",
    "        plate_meta = wells_df[mask]\n",
    "        \n",
    "        is_ctrl = plate_meta[TREATMENT_COL] == \"no_sgRNA\"\n",
    "        \n",
    "        # Plot Mutants (Filled Circles)\n",
    "        ax.scatter(plate_embed[~is_ctrl, 0], plate_embed[~is_ctrl, 1], \n",
    "                   color=plate_color_map[plate], marker='o', s=60, alpha=0.6, \n",
    "                   label=f\"{plate} (Mutant)\")\n",
    "        \n",
    "        # Plot Controls (Open Squares)\n",
    "        ax.scatter(plate_embed[is_ctrl, 0], plate_embed[is_ctrl, 1], \n",
    "                   edgecolors=plate_color_map[plate], facecolors='none', \n",
    "                   marker='s', s=130, linewidths=2, label=f\"{plate} (Control)\")\n",
    "\n",
    "        # 4. Add labels\n",
    "        for i, row in enumerate(plate_meta.itertuples()):\n",
    "            label = f\"{row.Treatment}_{row.Plate.split('_')[-1]}\"\n",
    "            texts.append(ax.text(plate_embed[i, 0], plate_embed[i, 1], label, \n",
    "                                 fontsize=6, color=plate_color_map[plate]))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f\"{config['name']}\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Move legend to the side if it gets too crowded with 6+ plates\n",
    "    if idx == 0:\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), markerscale=1, fontsize=8, ncol=1)\n",
    "    \n",
    "    # Adjust text to prevent overlapping labels\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.3))\n",
    "\n",
    "plt.suptitle(\"Combined UMAP: Multi-Plate Analysis\", fontsize=24, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
