{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a49fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce03760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all Excel sheets...\n",
      "Scanning directory: /media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset/inputs/images\n",
      "DONE! Found 10 sites.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- LINUX PATHS ---\n",
    "root_dir = Path(\"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset/inputs/images\")\n",
    "excel_path = Path(\"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset/inputs/images/MetaData_Bsubt_KD_screen.xlsx\")\n",
    "output_file = Path(\"/media/arnout/Elements1/groteEdeepprofilerdingen/deepprofileroutputsetc/testset/inputs/metadata/index.csv\")\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def normalize_well_id(well):\n",
    "    \"\"\"Converts A1 -> A01, A11 -> A11\"\"\"\n",
    "    match = re.match(r\"([a-zA-Z])(\\d+)\", str(well).strip())\n",
    "    if match:\n",
    "        letter = match.group(1).upper()\n",
    "        number = int(match.group(2))\n",
    "        return f\"{letter}{number:02d}\"\n",
    "    return str(well).strip()\n",
    "\n",
    "def extract_gene(text):\n",
    "    if pd.isna(text): return \"Unknown\"\n",
    "    match = re.search(r'Gene target:\\s*([\\w-]+)', str(text))\n",
    "    return match.group(1) if match else \"Unknown\"\n",
    "\n",
    "# --- 1. LOAD ALL EXCEL SHEETS ---\n",
    "print(\"Loading all Excel sheets...\")\n",
    "# sheet_name=None loads all sheets into a dictionary: {sheet_name: dataframe}\n",
    "excel_dict = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Process each sheet into a treatment map\n",
    "# Final structure: { 'PLATE_T2': {'A01': 'GeneA', 'A02': 'GeneB'}, 'PLATE_T3': {...} }\n",
    "plate_treatment_maps = {}\n",
    "\n",
    "for sheet_name, df in excel_dict.items():\n",
    "    if 'Strain_name' in df.columns and 'Position_microscopy' in df.columns:\n",
    "        df['Treatment'] = df['Strain_name'].apply(extract_gene)\n",
    "        # Create a map for THIS specific sheet/plate\n",
    "        current_map = dict(zip(\n",
    "            df['Position_microscopy'].apply(normalize_well_id), \n",
    "            df['Treatment']\n",
    "        ))\n",
    "        plate_treatment_maps[sheet_name.strip()] = current_map\n",
    "\n",
    "# --- 2. BUILD THE INDEX ---\n",
    "all_rows = []\n",
    "file_pattern = re.compile(r'Sample_(?P<well>[A-Z][0-9]+)_XY(?P<site>[0-9]+)_C(?P<chan>[0-9]+)')\n",
    "\n",
    "print(f\"Scanning directory: {root_dir}\")\n",
    "\n",
    "for plate_folder in os.listdir(root_dir):\n",
    "    if \"PLATE\" not in plate_folder.upper():\n",
    "        continue\n",
    "    \n",
    "    plate_path = root_dir / plate_folder\n",
    "    if not plate_path.is_dir(): continue\n",
    "    \n",
    "    # Get the specific treatment map for this plate\n",
    "    # We use .get() in case the folder name doesn't match the sheet name perfectly\n",
    "    current_plate_map = plate_treatment_maps.get(plate_folder.strip(), {})\n",
    "    \n",
    "    if not current_plate_map:\n",
    "        print(f\"Warning: No Excel sheet found matching folder name '{plate_folder}'\")\n",
    "    \n",
    "    for well_folder in os.listdir(plate_path):\n",
    "        if not well_folder.startswith(\"Sample_\"):\n",
    "            continue\n",
    "            \n",
    "        well_path = plate_path / well_folder\n",
    "        raw_well_id = well_folder.replace(\"Sample_\", \"\")  # \"A1\"\n",
    "        lookup_well_id = normalize_well_id(raw_well_id)    # \"A01\"\n",
    "        \n",
    "        sites = {} \n",
    "        for filename in os.listdir(well_path):\n",
    "            if not filename.lower().endswith((\".tiff\", \".tif\")):\n",
    "                continue\n",
    "            match = file_pattern.search(filename)\n",
    "            if match:\n",
    "                site_num = match.group('site')\n",
    "                channel_num = f\"C{match.group('chan')}\"\n",
    "                if site_num not in sites: sites[site_num] = {}\n",
    "                sites[site_num][channel_num] = f\"{plate_folder}/{well_folder}/{filename}\"\n",
    "\n",
    "        for site_id, channels in sites.items():\n",
    "            row = {\n",
    "                \"Metadata_Plate\": plate_folder,\n",
    "                \"Metadata_Well\": raw_well_id,\n",
    "                \"Metadata_Site\": int(site_id),\n",
    "                \"Treatment\": current_plate_map.get(lookup_well_id, \"Unknown\"),\n",
    "                \"Replicate\": 1 \n",
    "            }\n",
    "            row.update(channels)\n",
    "            all_rows.append(row)\n",
    "\n",
    "# --- 3. SAVE ---\n",
    "if not all_rows:\n",
    "    print(\"!!! NO IMAGES FOUND !!!\")\n",
    "else:\n",
    "    df_final = pd.DataFrame(all_rows)\n",
    "    channel_cols = sorted([c for c in df_final.columns if c.startswith(\"C\")], \n",
    "                          key=lambda x: int(x[1:]) if x[1:].isdigit() else 0)\n",
    "    final_cols = [\"Metadata_Plate\", \"Metadata_Well\", \"Metadata_Site\", \"Treatment\", \"Replicate\"] + channel_cols\n",
    "    \n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_final[final_cols].to_csv(output_file, index=False)\n",
    "    \n",
    "    unknown_count = len(df_final[df_final[\"Treatment\"] == \"Unknown\"])\n",
    "    print(f\"DONE! Found {len(df_final)} sites.\")\n",
    "    if unknown_count > 0:\n",
    "        print(f\"Warning: {unknown_count} sites have 'Unknown' treatment. Check if sheet names match folder names exactly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39570ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all Excel sheets...\n",
      "Scanning for selected plates in: /media/arnout/Elements1/Thesis/Screen crispri quality checked\n",
      "Processing PLATE2_T0...\n",
      "Warning: No Excel sheet found for 'PLATE2_T0'\n",
      "Processing PLATE2_T1...\n",
      "Processing PLATE2_T2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS! index.csv created with 3977 sites from 3 plates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "root_dir = Path(\"/media/arnout/Elements1/Thesis/Screen crispri quality checked\")\n",
    "excel_path = Path(\"/media/arnout/Elements1/Thesis/Screen crispri quality checked/MetaData_Bsubt_KD_screen.xlsx\")\n",
    "output_file = Path(\"/media/arnout/Elements1/Thesis/project_neighboursT20/inputs/metadata/index5.csv\")            #als ik hier index2 schreef werkte het plots wel , anders nam die de oude met t1t2\n",
    "\n",
    "# --- PLATE SELECTION ---\n",
    "# Only plates in this list will be added to your index.csv\n",
    "#PLATES_TO_INCLUDE = [\"PLATE1_T0\", \"PLATE1_T1\"] \n",
    "PLATES_TO_INCLUDE = [\"PLATE2_T0\", \"PLATE2_T1\", \"PLATE2_T2\" ] \n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def normalize_well_id(well):\n",
    "    \"\"\"Converts A1 -> A01, A11 -> A11\"\"\"\n",
    "    match = re.match(r\"([a-zA-Z])(\\d+)\", str(well).strip())\n",
    "    if match:\n",
    "        letter = match.group(1).upper()\n",
    "        number = int(match.group(2))\n",
    "        return f\"{letter}{number:02d}\"\n",
    "    return str(well).strip()\n",
    "\n",
    "def extract_gene(text):\n",
    "    if pd.isna(text): return \"Unknown\"\n",
    "    match = re.search(r'Gene target:\\s*([\\w-]+)', str(text))\n",
    "    return match.group(1) if match else \"Unknown\"\n",
    "\n",
    "# --- 1. LOAD ALL EXCEL SHEETS ---\n",
    "print(\"Loading all Excel sheets...\")\n",
    "excel_dict = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "plate_treatment_maps = {}\n",
    "for sheet_name, df in excel_dict.items():\n",
    "    s_name = sheet_name.strip()\n",
    "    if s_name in PLATES_TO_INCLUDE:  # Only process relevant sheets\n",
    "        if 'Strain_name' in df.columns and 'Position_microscopy' in df.columns:\n",
    "            df['Treatment'] = df['Strain_name'].apply(extract_gene)\n",
    "            current_map = dict(zip(\n",
    "                df['Position_microscopy'].apply(normalize_well_id), \n",
    "                df['Treatment']\n",
    "            ))\n",
    "            plate_treatment_maps[s_name] = current_map\n",
    "\n",
    "# --- 2. BUILD THE INDEX ---\n",
    "all_rows = []\n",
    "file_pattern = re.compile(r'Sample_(?P<well>[A-Z][0-9]+)_XY(?P<site>[0-9]+)_C(?P<chan>[0-9]+)')\n",
    "\n",
    "print(f\"Scanning for selected plates in: {root_dir}\")\n",
    "\n",
    "for plate_folder in PLATES_TO_INCLUDE:\n",
    "    plate_path = root_dir / plate_folder\n",
    "    \n",
    "    if not plate_path.exists():\n",
    "        print(f\"Skipping {plate_folder}: Folder not found on disk.\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing {plate_folder}...\")\n",
    "    current_plate_map = plate_treatment_maps.get(plate_folder, {})\n",
    "    \n",
    "    if not current_plate_map:\n",
    "        print(f\"Warning: No Excel sheet found for '{plate_folder}'\")\n",
    "    \n",
    "    for well_folder in os.listdir(plate_path):\n",
    "        if not well_folder.startswith(\"Sample_\"):\n",
    "            continue\n",
    "            \n",
    "        well_path = plate_path / well_folder\n",
    "        raw_well_id = well_folder.replace(\"Sample_\", \"\")\n",
    "        lookup_well_id = normalize_well_id(raw_well_id)\n",
    "        \n",
    "        sites = {} \n",
    "        for filename in os.listdir(well_path):\n",
    "            if not filename.lower().endswith((\".tiff\", \".tif\")):\n",
    "                continue\n",
    "            match = file_pattern.search(filename)\n",
    "            if match:\n",
    "                site_num = match.group('site')\n",
    "                channel_num = f\"C{match.group('chan')}\"\n",
    "                if site_num not in sites: sites[site_num] = {}\n",
    "                sites[site_num][channel_num] = f\"{plate_folder}/{well_folder}/{filename}\"\n",
    "\n",
    "        for site_id, channels in sites.items():\n",
    "            row = {\n",
    "                \"Metadata_Plate\": plate_folder,\n",
    "                \"Metadata_Well\": raw_well_id,\n",
    "                \"Metadata_Site\": int(site_id),\n",
    "                \"Treatment\": current_plate_map.get(lookup_well_id, \"Unknown\"),\n",
    "                \"Replicate\": 1 \n",
    "            }\n",
    "            row.update(channels)\n",
    "            all_rows.append(row)\n",
    "\n",
    "# --- 3. SAVE ---\n",
    "if not all_rows:\n",
    "    print(\"!!! NO IMAGES FOUND FOR THE SELECTED PLATES !!!\")\n",
    "else:\n",
    "    df_final = pd.DataFrame(all_rows)\n",
    "    # Filter columns to only include those present in the data\n",
    "    existing_channels = sorted([c for c in df_final.columns if c.startswith(\"C\")], \n",
    "                               key=lambda x: int(x[1:]) if x[1:].isdigit() else 0)\n",
    "    \n",
    "    final_cols = [\"Metadata_Plate\", \"Metadata_Well\", \"Metadata_Site\", \"Treatment\", \"Replicate\"] + existing_channels\n",
    "    \n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_final[final_cols].to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nSUCCESS! index.csv created with {len(df_final)} sites from {len(df_final['Metadata_Plate'].unique())} plates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#met emptyrowcleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all Excel sheets...\n",
      "Scanning for selected plates in: /media/arnout/Elements1/Thesis/Screen crispri quality checked\n",
      "Processing PLATE2_T0...\n",
      "Processing PLATE2_T1...\n",
      "Processing PLATE2_T2...\n",
      "\n",
      "[CLEANING] Removing 16 rows containing empty/missing fields:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/arnout/miniconda3/envs/dp_analysis/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata_Plate Metadata_Well  Metadata_Site\n",
      "     PLATE2_T0            D9              0\n",
      "     PLATE2_T0            G7              0\n",
      "     PLATE2_T0            B2              3\n",
      "     PLATE2_T0            B4             13\n",
      "     PLATE2_T0            B5              0\n",
      "     PLATE2_T0            C3              0\n",
      "     PLATE2_T0            C5              0\n",
      "     PLATE2_T0            C6              0\n",
      "     PLATE2_T0           D10              0\n",
      "     PLATE2_T0            D2              1\n",
      "     PLATE2_T0            D5              0\n",
      "     PLATE2_T0            D6              0\n",
      "     PLATE2_T1            E4              0\n",
      "     PLATE2_T1           C11              0\n",
      "     PLATE2_T1            D2              0\n",
      "     PLATE2_T2            D7              5\n",
      "\n",
      "SUCCESS! index.csv created at: /media/arnout/Elements1/Thesis/project_neighboursT20/inputs/metadata/index5.csv\n",
      "Final summary: 3961 sites kept | 16 rows removed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "root_dir = Path(\"/media/arnout/Elements1/Thesis/Screen crispri quality checked\")\n",
    "excel_path = Path(\"/media/arnout/Elements1/Thesis/Screen crispri quality checked/MetaData_Bsubt_KD_screen.xlsx\")\n",
    "output_file = Path(\"/media/arnout/Elements1/Thesis/project_neighboursT20/inputs/metadata/index.csv\")\n",
    "\n",
    "# --- PLATE SELECTION ---\n",
    "PLATES_TO_INCLUDE = [\"PLATE2_T0\", \"PLATE2_T1\", \"PLATE2_T2\"] \n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def normalize_well_id(well):\n",
    "    \"\"\"Converts A1 -> A01, A11 -> A11\"\"\"\n",
    "    match = re.match(r\"([a-zA-Z])(\\d+)\", str(well).strip())\n",
    "    if match:\n",
    "        letter = match.group(1).upper()\n",
    "        number = int(match.group(2))\n",
    "        return f\"{letter}{number:02d}\"\n",
    "    return str(well).strip()\n",
    "\n",
    "def extract_gene(text):\n",
    "    if pd.isna(text) or str(text).strip() == \"\": return \"Unknown\"\n",
    "    match = re.search(r'Gene target:\\s*([\\w-]+)', str(text))\n",
    "    return match.group(1) if match else \"Unknown\"\n",
    "\n",
    "# --- 1. LOAD ALL EXCEL SHEETS ---\n",
    "print(\"Loading all Excel sheets...\")\n",
    "excel_dict = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "plate_treatment_maps = {}\n",
    "for sheet_name, df in excel_dict.items():\n",
    "    s_name = sheet_name.strip()\n",
    "    if s_name in PLATES_TO_INCLUDE:\n",
    "        if 'Strain_name' in df.columns and 'Position_microscopy' in df.columns:\n",
    "            df['Treatment'] = df['Strain_name'].apply(extract_gene)\n",
    "            current_map = dict(zip(\n",
    "                df['Position_microscopy'].apply(normalize_well_id), \n",
    "                df['Treatment']\n",
    "            ))\n",
    "            plate_treatment_maps[s_name] = current_map\n",
    "\n",
    "# --- 2. BUILD THE INDEX ---\n",
    "all_rows = []\n",
    "file_pattern = re.compile(r'Sample_(?P<well>[A-Z][0-9]+)_XY(?P<site>[0-9]+)_C(?P<chan>[0-9]+)')\n",
    "\n",
    "print(f\"Scanning for selected plates in: {root_dir}\")\n",
    "\n",
    "for plate_folder in PLATES_TO_INCLUDE:\n",
    "    plate_path = root_dir / plate_folder\n",
    "    \n",
    "    if not plate_path.exists():\n",
    "        print(f\"Skipping {plate_folder}: Folder not found on disk.\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing {plate_folder}...\")\n",
    "    current_plate_map = plate_treatment_maps.get(plate_folder, {})\n",
    "    \n",
    "    if not current_plate_map:\n",
    "        print(f\"Warning: No Excel sheet found for '{plate_folder}'\")\n",
    "    \n",
    "    for well_folder in os.listdir(plate_path):\n",
    "        if not well_folder.startswith(\"Sample_\"):\n",
    "            continue\n",
    "            \n",
    "        well_path = plate_path / well_folder\n",
    "        raw_well_id = well_folder.replace(\"Sample_\", \"\")\n",
    "        lookup_well_id = normalize_well_id(raw_well_id)\n",
    "        \n",
    "        sites = {} \n",
    "        for filename in os.listdir(well_path):\n",
    "            if not filename.lower().endswith((\".tiff\", \".tif\")):\n",
    "                continue\n",
    "            match = file_pattern.search(filename)\n",
    "            if match:\n",
    "                site_num = match.group('site')\n",
    "                channel_num = f\"C{match.group('chan')}\"\n",
    "                if site_num not in sites: sites[site_num] = {}\n",
    "                sites[site_num][channel_num] = f\"{plate_folder}/{well_folder}/{filename}\"\n",
    "\n",
    "        for site_id, channels in sites.items():\n",
    "            row = {\n",
    "                \"Metadata_Plate\": plate_folder,\n",
    "                \"Metadata_Well\": raw_well_id,\n",
    "                \"Metadata_Site\": int(site_id),\n",
    "                \"Treatment\": current_plate_map.get(lookup_well_id, \"Unknown\"),\n",
    "                \"Replicate\": 1 \n",
    "            }\n",
    "            row.update(channels)\n",
    "            all_rows.append(row)\n",
    "\n",
    "# --- 3. CLEANING AND SAVING ---\n",
    "if not all_rows:\n",
    "    print(\"!!! NO IMAGES FOUND FOR THE SELECTED PLATES !!!\")\n",
    "else:\n",
    "    df_final = pd.DataFrame(all_rows)\n",
    "    \n",
    "    # Organize columns\n",
    "    existing_channels = sorted([c for c in df_final.columns if c.startswith(\"C\")], \n",
    "                               key=lambda x: int(x[1:]) if x[1:].isdigit() else 0)\n",
    "    final_cols = [\"Metadata_Plate\", \"Metadata_Well\", \"Metadata_Site\", \"Treatment\", \"Replicate\"] + existing_channels\n",
    "    df_final = df_final[final_cols]\n",
    "\n",
    "    # A. Report on \"Unknown\" Treatments\n",
    "    unknown_mask = df_final['Treatment'] == \"Unknown\"\n",
    "    num_unknown = unknown_mask.sum()\n",
    "    if num_unknown > 0:\n",
    "        print(f\"\\n[NOTICE] {num_unknown} sites were assigned 'Unknown' treatment (missing in Excel).\")\n",
    "\n",
    "    # B. Convert truly empty strings/whitespace to NaN so they can be dropped\n",
    "    df_final = df_final.replace(r'^\\s*$', pd.NA, regex=True)\n",
    "\n",
    "    # C. Identify rows with ANY missing value (NaN or empty)\n",
    "    initial_count = len(df_final)\n",
    "    rows_with_nan = df_final.isnull().any(axis=1)\n",
    "\n",
    "    if rows_with_nan.any():\n",
    "        print(f\"\\n[CLEANING] Removing {rows_with_nan.sum()} rows containing empty/missing fields:\")\n",
    "        # Print details of what is being removed\n",
    "        print(df_final[rows_with_nan][[\"Metadata_Plate\", \"Metadata_Well\", \"Metadata_Site\"]].to_string(index=False))\n",
    "        \n",
    "        # Keep only the rows that are NOT missing data\n",
    "        df_final = df_final[~rows_with_nan].copy()\n",
    "    else:\n",
    "        print(\"\\n[CLEANING] No empty fields found. All rows kept.\")\n",
    "\n",
    "    # D. Final Save\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nSUCCESS! index.csv created at: {output_file}\")\n",
    "    print(f\"Final summary: {len(df_final)} sites kept | {initial_count - len(df_final)} rows removed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
